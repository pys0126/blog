<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Python网易职教云（MooC）刷课</title>
    <url>/cl27mwrhj0001u4jxcisd61a4-Fuck-Ivce/</url>
    <content><![CDATA[<h1 id="Fuck-MooC-Py"><a href="#Fuck-MooC-Py" class="headerlink" title="Fuck-MooC-Py"></a>Fuck-MooC-Py</h1><p>利用Python实现网易职教云（MooC）自动刷课和自动查题，代码位于：</p>
<ul>
<li><a href="https://e.coding.net/darkabyss/fuck-icve/Fuck-Icve.git">Fuck-MooC-Py（国内访问）</a></li>
<li><a href="https://github.com/pys0126/Fuck-Icve.git">Fuck-MooC-Py（国外访问）</a></li>
</ul>
<p>目前实现的功能：</p>
<ul>
<li>过PPT</li>
<li>自动查题</li>
</ul>
<p>预计实现的功能：</p>
<ul>
<li>自动答题</li>
<li><del>刷视频</del>（没研究好视频的反爬机制）</li>
</ul>
<span id="more"></span>

<h1 id="1-效果"><a href="#1-效果" class="headerlink" title="1.效果"></a>1.效果</h1><p><strong>自动查题：</strong><br><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/HJO%5BTUO%7BZ%25K%7B_%60B4TD%7B%40PUO.png!vip" alt="自动查题"></p>
<p><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/YL0%252E(%25UC%5BI%24%7DRTW%7DO)L37.png!vip" alt="答题分数"></p>
<p><strong>过PPT：</strong><br><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/QQ%E6%88%AA%E5%9B%BE20220108175414.png" alt="过ppt"></p>
<h1 id="2-使用"><a href="#2-使用" class="headerlink" title="2.使用"></a>2.使用</h1><h2 id="2-1-修改必须参数"><a href="#2-1-修改必须参数" class="headerlink" title="2.1 修改必须参数"></a>2.1 修改必须参数</h2><p>下图是需要修改的参数：<br><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/QQ%E6%88%AA%E5%9B%BE20220108192758.png" alt="参数"></p>
<p><strong>chatiba_cookie：</strong></p>
<p>去<a href="https://chatiba.com/">查题吧</a>注册一个账户，然后登录在查题吧主页面按F12找到网络选项然后刷新一次网页，点击第一个包，找到cookie，将它的值复制下来填入脚本相应位置。<br><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/QQ%E5%9B%BE%E7%89%8720220108195651.png" alt="chatiba_cookie"></p>
<p><strong>k_user和k_pwd：</strong><br>就是你的职教云账号和密码，将其填入脚本相应位置。</p>
<h2 id="2-2-运行"><a href="#2-2-运行" class="headerlink" title="2.2 运行"></a>2.2 运行</h2><p>用python运行脚本后会提示你填入验证码，验证码会在脚本执行的时候保存到脚本当前目录下，名称为：<code>verifycode.png</code>，填入验证码后就可以按照自己的需求选择课程了，如图：</p>
<p><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/QQ%E6%88%AA%E5%9B%BE20220108174641.png" alt="验证码"></p>
<p><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/PL_3%60%25U_9W0I%7DFPR3PY~YSE.png" alt="运行"></p>
<p>上图可以看到默认是启用了自动保存查询答案，想要相应的功能将其取消注释就行，最后两个功能可以配合使用，如图：</p>
<p><img src="https://cdn.lovepp.xyz/blog/Fuck-Icve/1O%60R%40%248HAM61UG1%5DYA7J5.png" alt="配合"></p>
]]></content>
      <categories>
        <category>Python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Python在520给女友微信定时批量发送99条情话</title>
    <url>/cl27mwrhw0003u4jx7y748zzw-page1/</url>
    <content><![CDATA[<h1 id="阿巴阿巴阿巴"><a href="#阿巴阿巴阿巴" class="headerlink" title="阿巴阿巴阿巴"></a>阿巴阿巴阿巴</h1><p>520 到了（迟到的详解），如何大批量给女友发情话呢？首先得有情话吧，情话哪里来呢？我找到了一个情话 api，请求地址：<a href="https://api.shadiao.app/chp">https://api.shadiao.app/chp</a> ,那么如何获取情话通过微信发送给女友呢？请看一下详细步骤</p>
<span id="more"></span>

<h1 id="请求情话-API"><a href="#请求情话-API" class="headerlink" title="请求情话 API"></a>请求情话 API</h1><p>首先得导入<strong>Requests</strong>库，如果没有在 cmd 安装：<code>pip3 install requests</code>， 然后先创建一个空列表 content 用于存储情话，创建一个 Sessions 用于持续访问（在这里其实没用），再将网址赋值给 url 变量，因为该 api 使用 GET 请求，所以使用 get 方法请求这个 api 地址，然后用列表的 addend 方法保存进 content，最后自定义一个函数封装，这里我自定义一个 parse 函数</p>
<pre><code class="python">import requests

content = []

def parse():
    Sessions = requests.session()
    url = &quot;https://api.shadiao.app/chp&quot;
    re = Sessions.get(url=url)
    content.append(re.json()[&quot;data&quot;][&quot;text&quot;])
</code></pre>
<h1 id="发送微信消息"><a href="#发送微信消息" class="headerlink" title="发送微信消息"></a>发送微信消息</h1><p>导入 itchat 库提供的微信接口来查找好友并发送消息（该库需要通过 pip 安装），然后用 auto_login 方法登录微信，然后添加 hotReload 参数并赋值为 True 用于存储登录信息，然后用 search_friends 方法查找你女友的备注名称并赋值给 user，然后用 send 方法来发送消息，该方法第一个参数是需要发送的信息也就是 content 列表中的情话，再填入一个 toUserName 参数为需要发送给谁也就是 user 的信息，但是 user 的信息的是一个列表套字典有很多参数，我们只需要第一个字典中的 UserName 的值：<code>user[0][&quot;UserName&quot;]</code>，最后自定义一个函数封装，这里我自定义一个 sen_msg 函数，但是需要设置一个获取列表下标的参数，我这里设置为 size，因为后面需要循环发送 99 条，不可能发个情话列表过去吧，所以发送的消息应为：<code>content[size]</code></p>
<pre><code class="python">import itchat

def sen_msg(size):
    itchat.auto_login(hotReload=True)
    user = itchat.search_friends(&quot;这里为你女友的备注&quot;)
    itchat.send(content[size], toUserName=user[0][&quot;UserName&quot;])
</code></pre>
<h1 id="启动函数"><a href="#启动函数" class="headerlink" title="启动函数"></a>启动函数</h1><p>用 for 循环请求 99 次 api，将 99 条情话存入 content，并通过微信发送给女友，最后自定义一个函数封装，这里我自定义一个 sen_msg 函数</p>
<pre><code class="python">def run():
    for i in range(99):
        parse()
        sen_msg(size=i)
</code></pre>
<h1 id="定时发送"><a href="#定时发送" class="headerlink" title="定时发送"></a>定时发送</h1><p>这里导入一个 schedule 第三方库（该库需要通过 pip 安装），该库是个调度器，我们用它来创建一个定时任务，用<code>every().thursday.at(&quot;13:14&quot;).do(run)</code>方法在星期五的 13 点 14 分运行 run 函数，然后用 run_pending 方法运行在 while 循环中并每秒检查一次时间，所以需要导入 time，用 sleep 方法等待一秒</p>
<pre><code class="python">import schedule
import time

schedule.every().thursday.at(&quot;13:14&quot;).do(run)  # 星期四的13:14发一次
while True:
    schedule.run_pending()
    time.sleep(1)
</code></pre>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><p>因为运行 sen_msg 函数时会登录微信一次，但是在定时的那个时间不一定在电脑前，所以我们将<code>itchat.auto_login(hotReload=True)</code>写在开头，也就是运行该脚本的时候就登录一次，<code>hotReload=True</code>会保存我的登录信息</p>
<pre><code class="python">import requests
import schedule
import itchat
import time

content = []
Sessions = requests.session()
itchat.auto_login(hotReload=True)  # hotReload=True用于存储登录信息

# 请求情话api
def parse():
    url = &quot;https://api.shadiao.app/chp&quot;
    re = Sessions.get(url=url)
    content.append(re.json()[&quot;data&quot;][&quot;text&quot;])

# 发送微信消息
def sen_msg(size):
    print(content[size])
    user = itchat.search_friends(&quot;你女友的备注&quot;)
    itchat.send(content[size], toUserName=user[0][&quot;UserName&quot;])

# 启动
def run():
    for i in range(99):
        parse()
        sen_msg(size=i)

schedule.every().thursday.at(&quot;13:14&quot;).do(run)  # 星期四的13:14发一次
while True:
    schedule.run_pending()
    time.sleep(1)
</code></pre>
<p><strong>最终效果</strong>，<a href="https://github.com/pys0126/Python/blob/master/love.py">GitHub 地址</a><br><img src="https://img-blog.csdnimg.cn/20210522184007984.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTQxNDQzMw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>Python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下MySQL“root”用户远程登录配置</title>
    <url>/cl27mwric0007u4jx8vsjhwzk-page2/</url>
    <content><![CDATA[<p>1.进入mysql命令行执行：</p>
<pre><code class="shell">mysql&gt;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;你的密码&#39; WITH GRANT OPTION;
mysql&gt;FLUSH PRIVILEGES;
</code></pre>
<p>2.然后修改mysql配置文件：vim /etc/mysql/mysql.conf.d/mysqld.cnf，找到并将bind-address =127.0.0.1（大概在44行）注释掉：</p>
<pre><code class="shell">#bind-address           = 127.0.0.1
</code></pre>
<p>3.重启mysql服务，然后就可以远程登录了：</p>
<pre><code class="shell">$ sudo service mysql restart
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>填安装最新版本Kali-Linux的坑</title>
    <url>/cl27mwrij0009u4jx3q6yavoh-page3/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>1.安装20年后版本的Kali-Linux让我踩了好多“坑”，这篇文章能填上大部分的“坑”🤨… </p>
<h1 id="一-Kali安装显示cdrom没挂载解决"><a href="#一-Kali安装显示cdrom没挂载解决" class="headerlink" title="一.Kali安装显示cdrom没挂载解决"></a>一.Kali安装显示cdrom没挂载解决</h1><p>1.查看/目录下是否有cdrom,如果没有mkdir cdrom,或者删除rm -rf cdrom ,重新mkdir cdrom </p>
<p>2.执行blkid查看U盘的盘符是那个，带有kali live的为kali的镜像</p>
<p>3.当前安装的环境镜像U盘设备为/dev/sdb1</p>
<p>4.执行挂载命令：<span id="more"></span></p>
<p>如果sdb1的type 为vfat,则为<code>mount -t vfat /dev/sdb1 /cdrom</code></p>
<p>如果sdb1的type 为iso9660,则<code>mount -t iso9660 /dev/sdb1 /cdrom</code></p>
<p>5.mount 之后可以cd /cdrom，查看文件是否挂载</p>
<p>6.exit退出</p>
<p>注：blkid可以看到type类型，并且命令执行报无效参数，表示没写对，而非命令不存在。另外进入shell的快捷键为ALT+F2,或者Crtl+ALT+F2，Crtl+ATL+F5回到安装界面</p>
<p>或者根据拔插U盘判断设备是哪个</p>
<h1 id="二-声音设备显示伪输出"><a href="#二-声音设备显示伪输出" class="headerlink" title="二.声音设备显示伪输出"></a>二.声音设备显示伪输出</h1><p>终端输入以下命令：</p>
<pre><code class="plain">$ echo “options snd-hda-intel dmic_detect=0” | sudo tee -a /etc/modprobe.d/alsa-base.conf
$ echo “blacklist snd_soc_skl” | sudo tee -a /etc/modprobe.d/blacklist.conf
</code></pre>
<h1 id="三-安装Deepin-wine的QQ，微信"><a href="#三-安装Deepin-wine的QQ，微信" class="headerlink" title="三.安装Deepin-wine的QQ，微信"></a>三.安装Deepin-wine的QQ，微信</h1><p>添加32位支持：</p>
<pre><code class="shell">$ sudo dpkg --add-architecture i386 
</code></pre>
<p>添加deepin的软件源：</p>
<pre><code class="plain">deb http://mirrors.aliyun.com/deepin panda main contrib non-free
deb-src http://mirrors.aliyun.com/deepin panda main contrib non-free
</code></pre>
<p>然后更新软件源，提示签名验证错误，执行：</p>
<pre><code class="plain">$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 提示的公钥
</code></pre>
<p>安装deepin-win:</p>
<pre><code class="plain">$ apt install deepin-wine --fix-missing
</code></pre>
<p>安装中文字体:</p>
<pre><code class="plain">$ apt-get install xfonts-intl-chinese
$ apt-get install ttf-wqy-microhei
</code></pre>
<p>安装QQ和微信:</p>
<pre><code class="plain">$ sudo apt install deepin.com.qq.im deepin.com.wechat
</code></pre>
<p>注：安装Toplcons Redux以解决最小化消失的问题，如果执行微信过后出现黑块请参考：<br><a href="https://www.cnblogs.com/lanqie/p/11287057.html#2621990085">https://www.cnblogs.com/lanqie/p/11287057.html#2621990085</a></p>
<p>补充作者添加runrun.sh文件后执行以下命令：</p>
<pre><code class="shell">$ sudo chmod +x /opt/deepinwine/apps/Deepin-WeChat/runrun.sh
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Kali</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Kali</tag>
      </tags>
  </entry>
  <entry>
    <title>安卓手机免Root安装拥有图形界面的Kali NetHunter</title>
    <url>/cl27mwrin000au4jx7ge60f9h-page6/</url>
    <content><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h3 id="说明-：安卓版本小于安卓5-0无法正常运行，安装完成后理论上可以运行所有Kali工具，Kali-NetHunter是amr64内核。"><a href="#说明-：安卓版本小于安卓5-0无法正常运行，安装完成后理论上可以运行所有Kali工具，Kali-NetHunter是amr64内核。" class="headerlink" title="说明 ：安卓版本小于安卓5.0无法正常运行，安装完成后理论上可以运行所有Kali工具，Kali NetHunter是amr64内核。"></a>说明 ：安卓版本小于安卓5.0无法正常运行，安装完成后理论上可以运行所有Kali工具，Kali NetHunter是amr64内核。</h3><span id="more"></span>
<p><a href="https://wws.lanzous.com/iVJzzf7j24h"><strong>PDF离线教程</strong> </a></p>
<p><a href="https://wws.lanzous.com/iUpQXexj2ha">termux</a>（必须） </p>
<p><a href="https://wws.lanzous.com/ik4jJexj2ng">NetHunter Kex</a>（必须） </p>
<h1 id="1-配置Termux"><a href="#1-配置Termux" class="headerlink" title="1.配置Termux"></a>1.配置Termux</h1><h2 id="更新和安装工具"><a href="#更新和安装工具" class="headerlink" title="更新和安装工具"></a>更新和安装工具</h2><p>首先在开始之前先打开老王VPN或者其他可以翻墙的工具都可以，第一次打开老王VPN需要等一会，然后进入主界面后如图，点击连线即可，第一次开启可能会提示你是否启用VPN标识，直接点确实即可。<br>第一次启动Termux的时候需要从远程服务器加载数据，可能会比较慢，耐心等待一会就行，然后出现如下界面就行，如果出现其他提示就关闭Termux用运营商网络试试。 </p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/294c0dfb13e9769e3321a96679b14360.png#pic_center" alt="图片"></p>
<p>然后执行以下命令来更新Termux软件库，如果中途停住按回车就行，然后等待一会直到出现 “ $ ” 表示更新完成 </p>
<pre><code class="shell">$ apt update &amp;&amp; apt upgrade -y 
</code></pre>
<p>接下来安装基本工具，等会安装Kali所需的几个工具，执行以下命令等待安装完成即可（出现 “ $ ” 即可） </p>
<pre><code class="shell">$ apt install curl vim wget -y  
</code></pre>
<h2 id="美化及创建内部存贮软目录"><a href="#美化及创建内部存贮软目录" class="headerlink" title="美化及创建内部存贮软目录"></a>美化及创建内部存贮软目录</h2><p>然后安装一个终端美化工具，为什么安装这个呢，它不光是让界面好看，有个功能是可以创建手机存贮软目录，因为termux安装在根目录的，未Root用户是无法访问的，Termux也无法访问手机存贮目录，所以有了软目录就可以通过Termux访问手机存贮目录了，比如手机下载文件夹，废话不多说，执行以下命令即可安装，安装时可能会提示你给予存贮权限，点允许即可。 </p>
<pre><code class="shell">$ sh -c &quot;$(curl -fsSL https://github.com/Cabbagec/termux-ohmyzsh/raw/master/install.sh)&quot;  
</code></pre>
<p>如果不小心点了拒绝执行以下命令重新获取就行。 </p>
<pre><code class="shell">$ termux-setup-storage 
</code></pre>
<p>等待它自动安装，完成后会让你输入配色序号，分别是<strong>色彩样式</strong>和<strong>字体样式</strong>，我是如下设置。 </p>
<pre><code class="shell">... 
Enter a number, leave blank to not to change: 41 
... 
Enter a number, leave blank to not to change: 7 
</code></pre>
<h2 id="定制常用按键（可选）"><a href="#定制常用按键（可选）" class="headerlink" title="定制常用按键（可选）"></a>定制常用按键（可选）</h2><p>对于熟悉Linux的朋友可以配置这个，首先新建并编辑一个配置文件： </p>
<pre><code class="shell">$ vim ~/.termux/termux.properties 
</code></pre>
<p>按 “ i ” 进入编辑模式输入以下内容： </p>
<pre><code class="shell"># 可以自定义按键 
extra-keys = [ \ 
 [&#39;ESC&#39;,&#39;-&#39;,&#39;/&#39;,&#39;HOME&#39;,&#39;UP&#39;,&#39;END&#39;,&#39;PGUP&#39;,&#39;DEL&#39;], \ 
 [&#39;TAB&#39;,&#39;CTRL&#39;,&#39;ALT&#39;,&#39;LEFT&#39;,&#39;DOWN&#39;,&#39;RIGHT&#39;,&#39;PGDN&#39;,&#39;BKSP&#39;] \ 
] 
</code></pre>
<p>修改后点击ESC，然后直接输入 <strong>“ZZ” （一定要大写）</strong> 即可保存并退出，如果没有 <strong>ESC</strong> 那行扩展键，从屏幕左侧向右滑动会 显示隐藏式导航栏，长按左下角的 <strong>KEYBOARD</strong> 即可显示扩展键，接下来 重启Termux即可生效，如图：<br><img src="https://img-blog.csdnimg.cn/img_convert/e092d468058c8307a9522f9d0b9ea5a6.png#pic_center" alt="2" style="zoom:50%;" /></p>
<h1 id="2-开始安装Kali-NetHunter"><a href="#2-开始安装Kali-NetHunter" class="headerlink" title="2.开始安装Kali NetHunter"></a>2.开始安装Kali NetHunter</h1><p>下载Kali NetHunter镜像：<br><strong>谷歌网盘：</strong> <a href="https://drive.google.com/uc?id=13BjoGirO0xONNeJ2FO0PcH8HV-3McrbD&amp;export=download">https://drive.google.com/uc?id=13BjoGirO0xONNeJ2FO0PcH8HV-3McrbD&amp;export=download</a><br><strong>百度网盘：</strong> <a href="https://pan.baidu.com/s/1ew2dny6xX5x26f9wSZY6uQ">https://pan.baidu.com/s/1ew2dny6xX5x26f9wSZY6uQ</a>  提取码：wyml </p>
<p>如果用百度网盘下载需要设置默认下载目录为手机Download文件夹，如图：<br><img src="https://img-blog.csdnimg.cn/img_convert/cdc8f9e3d46cada4929e218e23b69bad.png#pic_center" alt="2" style="zoom:40%;" /><br>下载好后应该在手机Download目录下面，然后执行以下命令从Download目录移动镜像到Termux目录： </p>
<pre><code class="shell">$ mv storage/downloads/kalifs-arm64-full.tar.xz ~/ 
</code></pre>
<p>这里可能会出现下面错误：</p>
<pre><code class="shell">mv:cannot stat &#39;storage/downloads/kalifs-arm64-full.tar.xz&#39;: No such file or directory
</code></pre>
<p>如果出现这个错误，运行以下命令即可：</p>
<pre><code class="shell">$ mv storage/shared/download/我的资源/Linux/kalifs-arm64-full.tar.xz ~/
</code></pre>
<p>**注意：镜像文件有点大，移动过程会有点慢，请耐心等待出现 “ $ ” 即可。 **<br>获取并执行安装脚本： </p>
<pre><code class="shell">$ wget -O install-nethunter-termux https://pys0126.github.io/dlc/install-nethunter-termux
$ chmod +x install-nethunter-termux 
$ ./install-nethunter-termux 
</code></pre>
<p>执行后可能会停住提示你:<code>[?] Existing image file found. Delete and download a new one? [y/N]</code>这里输入n回车即可，然后它会解压镜像，这个过程可能10-20分钟，请耐心等待，出现如下界面说明Kali已经安装成功了。<br><img src="https://img-blog.csdnimg.cn/img_convert/5b5514f385a385bf5a5b8dd46acd3b71.png#pic_center" alt="图片"></p>
<h1 id="3-使用Kali-NetHunter"><a href="#3-使用Kali-NetHunter" class="headerlink" title="3.使用Kali NetHunter"></a>3.使用Kali NetHunter</h1><h2 id="Kali-NetHunter启动前命令"><a href="#Kali-NetHunter启动前命令" class="headerlink" title="Kali NetHunter启动前命令"></a>Kali NetHunter启动前命令</h2><p><strong>注意：在使用Kali之前可以把老王VPN关了，以免影响网速。</strong> </p>
<p>在Termux执行以下命令之一： </p>
<pre><code class="shell">命令                  功能      
$nh                以普通用户启动Kali NetHunter命令行界面 
$nh kex passwd     配置KeX密码（仅在第一次使用图形界面前使用） 
$nh kex &amp;          建立Kali NetHunter图形界面普通用户会话 
$nh kex stop       停止Kali NetHunter图形界面普通用户会话（每次关闭后必须运行） 
# 一般常用以下命令 
$nh -r              以普通用户启动Kali NetHunter命令行界面 
$nh -r kex passwd   配置KeX密码（仅在第一次使用Root用户图形界面前使用） 
$nh -r kex &amp;        建立Kali NetHunter图形界面Root用户会话 
$nh -r kex stop        停止Kali NetHunter图形界面Root用户会话（每次关闭后必须运行） 
$nh -r kex kill     关闭所有KeX会话 
</code></pre>
<h2 id="使用图形化界面"><a href="#使用图形化界面" class="headerlink" title="使用图形化界面"></a>使用图形化界面</h2><p>不知道如何使用图像化界面？首先，执行： </p>
<pre><code class="shell">$nh -r kex passwd 
password:      #创建Kex密码，这里输入的密码是不显示的 
Verify:        #再次确认Kex密码，这里也不会显示 
</code></pre>
<p>如果出现 “ $ ” 表示创建成功，其他情况都说明两次输入密码不一致。然后使用以下命令开启图形界面会话。 </p>
<pre><code class="shell">$ nh -r kex &amp; 
</code></pre>
<p>出现下图表示开启成功，可以进行下一步操作。<br><img src="https://img-blog.csdnimg.cn/img_convert/8ca0c474d301fcfc24fec34e09f991e1.png#pic_center" alt="2" style="zoom:50%;" /></p>
<p>接下来打开 <strong>NetHunter KeX</strong> ，然后像下图设置，然后点击右上角 <strong>Connect</strong> 即可进入图形界面。 </p>
<img src="https://img-blog.csdnimg.cn/img_convert/c59b11e8004d0c835f3a7706096666a0.png#pic_center" alt="2" style="zoom:25%;" />

<h1 id="4-扩展"><a href="#4-扩展" class="headerlink" title="4.扩展"></a>4.扩展</h1><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>在图形界面下鼠标指针的操作为：滑动=移动鼠标；双击=鼠标左键；两指点击=鼠标右键</p>
<h2 id="安装kali默认工具"><a href="#安装kali默认工具" class="headerlink" title="安装kali默认工具"></a>安装kali默认工具</h2><p>如果需要Kali默认的工具的话需要确保手机剩余16GB空间，然后在**图形界面(如下图)**下打开终端，如图，然后点击右边的键盘标志打开键盘执行如下命令： </p>
<pre><code class="shell">root@localhost:~# sudo apt update &amp;&amp; sudo apt full-upgrade 
... #停住就输入y，后面再停住就回车，等待完成 
root@localhost:~# sudo apt install kali-linux-default 
... #停住就输入y，后面再停住就回车，等待完成 
</code></pre>
<img src="https://img-blog.csdnimg.cn/img_convert/85e90e4a5e6edd8282d57ac3429b43f4.png#pic_center" alt="2" style="zoom:70%;" />

<p><strong>安装到此如果还有什么问题QQ联系：1637566997</strong> </p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Kali</category>
        <category>安卓</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Kali</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>Manjaro[KDE]安装到使用</title>
    <url>/cl27mwrix000du4jx2gkc5e5h-page8/</url>
    <content><![CDATA[<h3 id="折腾基于Arch的Linux发行版：Manjaro-【KDE桌面】，本文有一些我在安装和使用Manjaro中所遇到的问题和解决方案，包括英特尔-英伟达双显卡的驱动问题。"><a href="#折腾基于Arch的Linux发行版：Manjaro-【KDE桌面】，本文有一些我在安装和使用Manjaro中所遇到的问题和解决方案，包括英特尔-英伟达双显卡的驱动问题。" class="headerlink" title="折腾基于Arch的Linux发行版：Manjaro 【KDE桌面】，本文有一些我在安装和使用Manjaro中所遇到的问题和解决方案，包括英特尔+英伟达双显卡的驱动问题。"></a>折腾基于Arch的Linux发行版：Manjaro 【KDE桌面】，本文有一些我在安装和使用Manjaro中所遇到的问题和解决方案，包括<strong>英特尔+英伟达双显卡</strong>的驱动问题。</h3><span id="more"></span>

<h1 id="1-安装前"><a href="#1-安装前" class="headerlink" title="1.安装前"></a>1.安装前</h1><p><strong>1.进入到grub界面，首先选择语言为Chinese–&gt;zh-CN</strong></p>
<p><strong>2.选择drives=nofree（带有英伟达显卡的务必选这个）</strong></p>
<h1 id="2-进行安装"><a href="#2-进行安装" class="headerlink" title="2.进行安装"></a>2.进行安装</h1><p><strong>主要是选择分区，分区步骤：</strong></p>
<p><strong>1.选择300M，格式为FAT32，挂载点为/boot/efi，标记为boot</strong></p>
<p><strong>2.选择15G，格式为exT4，挂载点为/opt</strong></p>
<p><strong>3.选择30G，格式为exT4，挂载点为/</strong></p>
<p><strong>4.选择剩余空间，格式为exT4，挂载点为/home</strong></p>
<p><strong>5.点击下一步，点继续安装</strong></p>
<p><strong>注意：最好空出几个G空间出来，不要问为什么</strong></p>
<h1 id="3-安装后"><a href="#3-安装后" class="headerlink" title="3.安装后"></a>3.安装后</h1><p><strong>1.更改为国内软件源</strong></p>
<pre><code class="shell">$ sudo pacman-mirrors -i -c China -m rank
</code></pre>
<p><strong>然后选择延迟最低的源，点击确定</strong><br><strong>2.更新软件源</strong></p>
<pre><code class="shell">$ sudo pacman -Syyu 
</code></pre>
<p><strong>3.安装第三方包管理器yay和vim</strong></p>
<pre><code class="shell">$ sudo pacman -S yay
$ yay -S vim
</code></pre>
<p>yay命令跟pacman命令用一样点参数，而且不用加sudo<br><strong>4.安装googlepinyin中文输入法</strong></p>
<pre><code class="shell">$ yay -S fcitx-im
$ yay -S fcitx-configtool
$ yay -S fcitx-googlepinyin
</code></pre>
<p>使用vim编辑～/.xprofile文件，加入一下文本：</p>
<pre><code class="shell">$ export GTK_IM_MODULE=fcitx
$ export QT_IM_MODULE=fcitx
$ export XMODIFIERS=&quot;@im=fcitx&quot;
</code></pre>
<p><strong>5.安装解包之内工具：</strong></p>
<pre><code class="shell">yay -S pkgconf fakeroot patch
</code></pre>
<p><strong>6.如果发现系统没有声音，声音设备显示伪输出，执行以下命令（有声音就不用看这条）</strong></p>
<pre><code class="shell">$ echo “options snd-hda-intel dmic_detect=0” | sudo tee -a /etc/modprobe.d/alsa-base.conf
$ echo “blacklist snd_soc_skl” | sudo tee -a /etc/modprobe.d/blacklist.conf
</code></pre>
<p><strong>7.完成以上操作就reboot</strong></p>
<h1 id="4-使用中"><a href="#4-使用中" class="headerlink" title="4.使用中"></a>4.使用中</h1><p><strong>1.科学上网</strong></p>
<p>Qv2ray:</p>
<p><a href="https://tlanyan.me/download.php?filename=/v2/linux/Qv2ray.v2.6.3.linux-x64.AppImage">免安装程序</a></p>
<p><a href="https://github.com/v2ray/v2ray-core/releases/download/v4.28.2/v2ray-linux-64.zip">v2ray内核</a></p>
<p>ssr-gtk:</p>
<p><a href="https://github.com/Baloneo/ssr-gtk">ssr-gtk</a>(需安装的包：media-control-indicator-git)</p>
<p><strong>2.解决下载软件时git clone很慢的情况</strong></p>
<p>配置git帐号信息</p>
<pre><code class="shell">$ git config --global user.name &quot;你的git名称&quot;
$ git config --global user.email 你的git邮箱
</code></pre>
<p>生成SSH密钥</p>
<pre><code class="sh">$ ssh-keygen -t rsa -C “你的git邮箱”    #一路回车
</code></pre>
<p>复制公钥</p>
<pre><code class="sh">$ cd .ssh/
$ cat id_rsa.pub   #将显示出来点公钥全部复制
</code></pre>
<p>进入你的github账户设置添加SSH密钥，设置git clone代理（每次开启代理都要设置，SSR端口默认为1080，Qv2ray默认为1089）</p>
<pre><code class="sh">$ git config --global http.proxy socks5://127.0.0.1:1080
$ git config --global https.proxy socks5://127.0.0.1:1080
</code></pre>
<p>确保打开了SSR或者Qv2ray全局代理模式，然后便可以快速的clone了<br><strong>3.yay安装出现错误解决</strong></p>
<p>如果出现以下错误</p>
<pre><code class="sh">fatal: 无法访问 &#39;***&#39;：OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to aur.archlinux.org:443
</code></pre>
<p>运行以下命令即可解决</p>
<pre><code class="sh">$ git config --global --unset http.proxy
#如果速度慢运行以下命令
$ git config --global http.proxy socks5://127.0.0.1:1080
$ git config --global https.proxy socks5://127.0.0.1:1080
</code></pre>
<p><strong>4.安装美化下载工具</strong></p>
<pre><code class="sh">$ yay -S ocs-url
</code></pre>
<p><strong>5.解决QQ/Tim闪退，打不了中文</strong></p>
<p>如果闪退，执行以下命令</p>
<pre><code class="sh">$ sudo pacman -S gnome-settings-daemon
$ sudo cp /etc/xdg/autostart/org.gnome.SettingsDaemon.XSettings.desktop   ~/.config/autostart
</code></pre>
<p>然后打开系统设置-&gt;开机或关机-&gt;自动启动-&gt;添加脚本-&gt;输入/usr/lib/gsd-xsettings，重启<br>如果发现打不了中文在‘/opt/deepinwine/apps/Deepin-TIM/run.sh’开头加入以下命令，并重启：</p>
<pre><code class="sh">export GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS=@im=fcitx
</code></pre>
<p>安装TIM</p>
<pre><code class="sh">$ yay -S deepin-wine-tim
</code></pre>
<p><strong>6.安装微信</strong></p>
<pre><code class="sh">$ yay -S deepin-wine-wechat
$ yay -S deepin-wine
</code></pre>
<p>修改以下两个文件的WINE_CMD的值</p>
<pre><code class="sh">$ sudo vim /opt/deepinwine/apps/Deepin-WeChat/run.sh
$ sudo vim /opt/deepinwine/tools/run.sh
# 改成WINE_CMD=&quot;deepin-wine&quot;
</code></pre>
<p><strong>7.解决网易云音乐无法加载问题（貌似能解决）</strong></p>
<pre><code class="shell">$ yay -S automake autoconf bison flex
$ yay -S gstreamer0.10-good-plugins
</code></pre>
<p><strong>8.英特尔+英伟达双显卡，使用英伟达显卡运行程序</strong><br>用终端在需要用英伟达显卡执行的程序前加入“prime-run”命令：</p>
<pre><code class="shell">$ prime-run &lt;程序名&gt;
</code></pre>
<p>如果要使用英伟达显卡运行steam里面的游戏，则设置该游戏的启动选项为：</p>
<pre><code class="shell">prime-run %command%
</code></pre>
<p><strong>9.出现Failed to connect to raw.githubusercontent.com:443的解决办法</strong><br>开启代理，1080需要换成你自己代理的端口(ssr)</p>
<pre><code class="shell">$ exportall_proxy=socks5://127.0.0.1:1080
</code></pre>
<p>关闭代理</p>
<pre><code class="shell">$ unset all_proxy
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Manjaro</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Manjaro</tag>
        <tag>双显卡</tag>
        <tag>KDE桌面</tag>
      </tags>
  </entry>
  <entry>
    <title>去TM的学习通</title>
    <url>/cl27mwrj1000eu4jx5hp18ekw-Fuck_CX/</url>
    <content><![CDATA[<p><strong>仅支持CQCIVC学院</strong>，目前的功能：过PPT任务，视频任务（16倍播放需自己设置网课扩展），捕获异常界面要求输入的验证码</p>
<span id="more"></span>

<p><a href="https://github.com/pys0126/Fuck_CX/archive/main.zip">下载地址</a></p>
<p><a href="https://github.com/pys0126/Fuck_CX">项目地址</a></p>
<h1 id="前提需要"><a href="#前提需要" class="headerlink" title="前提需要"></a>前提需要</h1><h2 id="安装Python3和相关依赖"><a href="#安装Python3和相关依赖" class="headerlink" title="安装Python3和相关依赖"></a>安装Python3和相关依赖</h2><ul>
<li>安装Python3<ul>
<li>Windows下载地址：<a href="https://www.python.org/downloads/release/python-379/">https://www.python.org/downloads/release/python-379/</a></li>
</ul>
</li>
<li>安装依赖：<ul>
<li>在命令行窗口运行<code>pip3 install -r requirements.txt</code><h2 id="下载Edge浏览器的webdriver"><a href="#下载Edge浏览器的webdriver" class="headerlink" title="下载Edge浏览器的webdriver"></a>下载Edge浏览器的webdriver</h2></li>
</ul>
</li>
<li>在Edge浏览器输入edge://version/查看版本，然后下载<strong>对应版本的Webdriver</strong></li>
<li>Webdriver下载地址：<a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/">https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/</a><h2 id="下载网课扩展"><a href="#下载网课扩展" class="headerlink" title="下载网课扩展"></a>下载网课扩展</h2></li>
<li>下载地址：<a href="https://github.com/CodFrm/cxmooc-tools/releases/download/v2.5.0/cxmooc-tools.zip">https://github.com/CodFrm/cxmooc-tools/releases/download/v2.5.0/cxmooc-tools.zip</a> （如何添加edge扩展自行百度）<h2 id="运行脚本"><a href="#运行脚本" class="headerlink" title="运行脚本"></a>运行脚本</h2></li>
<li>1、在脚本12行-14行设置好Webdriver路径，手机号，密码</li>
<li>2、在脚本路径下按住Shift+鼠标右键打开PowerShell，运行<code>python &#39;.\fuck_cx(requests+selenium).py&#39;</code></li>
</ul>
]]></content>
      <categories>
        <category>Python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>华为HCIA（Big Data）培训记录</title>
    <url>/cl27mwrvt0024u4jx87b394tx-2022-4-20/</url>
    <content><![CDATA[<h1 id="大数据概述-amp-解决办法"><a href="#大数据概述-amp-解决办法" class="headerlink" title="大数据概述&amp;解决办法"></a>大数据概述&amp;解决办法</h1><h2 id="大数据的特征（5v-1c）"><a href="#大数据的特征（5v-1c）" class="headerlink" title="大数据的特征（5v+1c）"></a>大数据的特征（5v+1c）</h2><ul>
<li>大量：数据量巨大，MB,GB,TB,PB</li>
<li>多样：数据类型多样，数据来源多样 数据来源：服务器日志、网站浏览信息、社交<br>结构化数据：表格数据 平台、摄像头信息<br>半结构化数据：网页html、xml<br>非结构化数据：视频、音频、图片、文字</li>
<li>高速：数据产生速度快、数据处理速度快</li>
<li>价值：价值密度低</li>
<li>准确：数据真实性</li>
<li>复杂：数据产生速度快、数据的类型多样等特征，导致做数据处理时处理过程变得很复杂</li>
</ul>
<span id="more"></span>

<h2 id="大数据处理流程"><a href="#大数据处理流程" class="headerlink" title="大数据处理流程"></a>大数据处理流程</h2><p>数据采集-&gt;数据预处理-&gt;数据存储-&gt;分析挖掘-&gt;数据可视化</p>
<h3 id="大数据任务类型"><a href="#大数据任务类型" class="headerlink" title="大数据任务类型"></a>大数据任务类型</h3><ul>
<li>IO密集型任务：大量输入输出请求的任务IO资源</li>
<li>计算密集型任务：有大量的计算要求，CPU资源</li>
<li>数据密集型任务：数据处理，并发数据处理</li>
</ul>
<h2 id="大数据的计算类型（数据处理类型）"><a href="#大数据的计算类型（数据处理类型）" class="headerlink" title="大数据的计算类型（数据处理类型）"></a>大数据的计算类型（数据处理类型）</h2><ul>
<li>批处理：一次处理一批量数据，处理的数据量大，但是延迟性高</li>
<li>流处理：一次处理一条数据，处理的数据量小，但是延迟性低</li>
<li>图处理：以图的形式展示数据，进行处理</li>
<li>查询分析计算：检索功能</li>
</ul>
<h2 id="大数据解决方案"><a href="#大数据解决方案" class="headerlink" title="大数据解决方案"></a>大数据解决方案</h2><p>Fusioninsight HD:部署在x86架构上<br>BigData pro:部署在ARM架构上<br>MapReduce Server（MRS）:部署华为云服务上</p>
<ul>
<li>高性能：支持自我研发的存储系统CarbonData</li>
<li>易运维：提供了可视化的管理界面</li>
<li>高安全：使用Kerborse &amp; Ldap实现认证管理和权限管理</li>
<li>低成本：按需购买，自定义配置底层架构性能</li>
</ul>
<h1 id="HDFS分布式文件系统"><a href="#HDFS分布式文件系统" class="headerlink" title="HDFS分布式文件系统"></a>HDFS分布式文件系统</h1><h2 id="HDFS-Hadoop分布式文件系统"><a href="#HDFS-Hadoop分布式文件系统" class="headerlink" title="HDFS (Hadoop分布式文件系统)"></a>HDFS (Hadoop分布式文件系统)</h2><ul>
<li>创建人:道格卡廷</li>
<li>起始原因:开发一个搜索引擎–&gt;存储问题(大量数据的存储)</li>
<li>google论文: GFS - google自身的分布式文件系统 <code>闭源</code></li>
</ul>
<h2 id="HDFS特性"><a href="#HDFS特性" class="headerlink" title="HDFS特性"></a>HDFS特性</h2><p>理论上HDFS存储可以无限扩展</p>
<ul>
<li>分布式:把多节点的存储系统结合为一一个整体对外提供服务(提高存储能力)</li>
<li>容错性:针对每个数据存储备份(默认3份)，备份存储分别存在不同的位置，如果备份或者数据有丢失，会再进行备份，保持一直都是3份</li>
<li>按块存储:块大小默认128M, 一个文件可以存储在多个块,<code>但是一个块只存储一个文件</code> <br><code>好处:数据丢失针对丢失的数据所属的块，只恢复当前块就可以</code></li>
<li>元数据:记录文件存储在哪些块,块存储在哪里等信息 <br>每个块都有一个元数据信息，并且元数据的大小是固定的150K</li>
</ul>
<h2 id="HDFS适用场景"><a href="#HDFS适用场景" class="headerlink" title="HDFS适用场景"></a>HDFS适用场景</h2><ul>
<li>可以做大文件</li>
<li>可以协助离线处理或批处理</li>
<li>流式数据访问机制</li>
</ul>
<h2 id="HDFS不适合做什么"><a href="#HDFS不适合做什么" class="headerlink" title="HDFS不适合做什么"></a>HDFS不适合做什么</h2><ul>
<li>不适合大量小文件存储</li>
<li>不适合做实时场景</li>
<li>不适合随机读写，可以做追加写</li>
</ul>
<h2 id="HDFS为什么不适合大量小文件存储"><a href="#HDFS为什么不适合大量小文件存储" class="headerlink" title="HDFS为什么不适合大量小文件存储"></a><code>HDFS为什么不适合大量小文件存储</code></h2><pre><code>(例: 10个文件，每个文件大小为20M)
</code></pre>
<ol>
<li>10个文件需要使用10个块，并且每个块只是用了20M空间—&gt; 存储空间浪费</li>
<li>有10个元数据，元数据150K</li>
<li>寻址时间增长</li>
</ol>
<p>不适合随机读写，可以做追加写</p>
<h2 id="HDFS系统架构"><a href="#HDFS系统架构" class="headerlink" title="HDFS系统架构"></a>HDFS系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img.png!vip" alt="HDFS系统架构"></p>
<ul>
<li>Client (客户端) :用户接口，用户通过Client连接到组件</li>
<li>NameNode (名称节点，主节点) :管理DataNode,并且接收用户请求,分发任务，存储元数据信息</li>
<li>DataNode (数据节点，从节点) :实际处理用户请求，维护自己的Block和实际存储位置映射关系</li>
<li>Block (块) : 数据存储</li>
</ul>
<h2 id="HDFS单NameNode的问题"><a href="#HDFS单NameNode的问题" class="headerlink" title="HDFS单NameNode的问题"></a>HDFS单NameNode的问题</h2><ul>
<li>单名称节点故障:整个集群都无法使用—&gt;HA(主备配置)</li>
<li>单名称节点性能瓶颈问题:并发处理的任务量有限—-&gt;联邦机制</li>
</ul>
<h2 id="HDFS-HA特性-主备配置"><a href="#HDFS-HA特性-主备配置" class="headerlink" title="HDFS HA特性(主备配置)"></a>HDFS HA特性(主备配置)</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_1.png!vip" alt="HA特性"></p>
<ul>
<li>active节点:对外提供服务</li>
<li>standby节点:不断备份active节点的数据，<code>当active宕机,standby会成为新的active</code></li>
<li>zookeeper监测主节点的状态，一旦发现故障，zookeeper就通知备用节点成为新的主节点</li>
</ul>
<h2 id="HDFS的联邦机制"><a href="#HDFS的联邦机制" class="headerlink" title="HDFS的联邦机制"></a>HDFS的联邦机制</h2><pre><code>各个NN之间是相互隔离的，维护自己的命名空间
</code></pre>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_2.png!vip" alt="联邦机制"></p>
<h2 id="HDFS元数据持久化-主备同步"><a href="#HDFS元数据持久化-主备同步" class="headerlink" title="HDFS元数据持久化(主备同步)"></a>HDFS元数据持久化(主备同步)</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_3.png!vip" alt="元数据持久化"></p>
<ol>
<li>备节点会通知主节点新建一个Editlog.new文件， 从这之后的操作都记录在.new文件中</li>
<li>备节点从主节点拷贝Editlog、Fsimage文件(只有第一 次需要 下载Fsimage,后续同步使用本地的)</li>
<li>将两个文件进行合并，生成Fsimage.ckpt文件</li>
<li>备节点将Fsimage.ckpt上传到主节点上</li>
<li>主节点接收到Fsimage.ckpt恢复成Fsimage</li>
<li>把Editlog.new重命名Editlog</li>
</ol>
<h2 id="HDFS副本机制-3份"><a href="#HDFS副本机制-3份" class="headerlink" title="HDFS副本机制 (3份)"></a>HDFS副本机制 (3份)</h2><ul>
<li>存储副本规则: </li>
</ul>
<ol>
<li>第一份副本存放在同一节点中(传输最快,但是如果节点故障，副本也会丢失)</li>
<li>第二份副本存放在同一机架的不同节点上(如果整个机架故障，副本也会丢失)</li>
<li>第三分副本存放在不同机架的其他节点上</li>
</ol>
<ul>
<li>副本距离公式:<code>优先选择的是距离小的</code></li>
</ul>
<ol>
<li>同节点的距离为0</li>
<li>同一机架不同节点的距离为2</li>
<li>不同机架的节点距离为4</li>
</ol>
<h2 id="HDFS读取流程"><a href="#HDFS读取流程" class="headerlink" title="HDFS读取流程"></a>HDFS读取流程</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_4.png!vip" alt="读取流程"></p>
<ol>
<li>Client向NameNode发起读取请求</li>
<li>NameNode接收到请求，反馈对应的元数据信息给Client</li>
<li>Client接收到反馈请求对应的DataNode <code>(如果Client本地有数据，优先从本地读取)</code></li>
<li>DataNode接收到请求，反馈数据内容给Client</li>
<li>关闭读取流</li>
</ol>
<h2 id="HDFS写入流程"><a href="#HDFS写入流程" class="headerlink" title="HDFS写入流程"></a>HDFS写入流程</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_5.png!vip" alt="写入流程"></p>
<ol>
<li>Client向NameNode发出写入请求</li>
<li>NameNode接收到请求后生成该文件的元数据信息，反馈DataNode信息给Client</li>
<li>Client接收到DataNode信息之后，请求相对应的DataNode</li>
<li>Client提交文件写入到对应的DataNode</li>
<li>DataNode接收到写入请求，执行写入</li>
<li>Client写入第一-个节点后，由第一个节点写入第二个节点，第二个节点写入第三个节点</li>
<li>写入完成后反馈元数据信息给Client</li>
<li>关闭读取流，NameNode更新元数据信息</li>
</ol>
<h1 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h1><pre><code>分布式服务应用，可以帮助其他分布式组件协调管理集群
</code></pre>
<h2 id="ZooKeeper的特性"><a href="#ZooKeeper的特性" class="headerlink" title="ZooKeeper的特性"></a>ZooKeeper的特性</h2><ul>
<li>分布式服务, ZooKeeper集群中有一半以上的节点存活集群才能正常运行</li>
<li>最终一致性:所有的节点对外提供的是同一个视图</li>
<li>实时性:实时获取、实时反馈应用状态</li>
<li>可靠性: 一条数据被-个节点接收到，就会被其他节点也接收</li>
<li>等待无关性:慢的或者失效的client请求，不会影响到其他客户端请求</li>
<li>原子性:最终状态只有成功或者失败</li>
</ul>
<h2 id="ZooKeeper集群主从选举-主备切换"><a href="#ZooKeeper集群主从选举-主备切换" class="headerlink" title="ZooKeeper集群主从选举/主备切换"></a>ZooKeeper集群主从选举/主备切换</h2><ul>
<li>选举: zookeeper内部投票选举,当节点得到一半以上的票数,它就会称为Leader,其他的节点都是Follower</li>
<li>主备切换:当leader出现故障,从其他的follower中重新选举新的leader</li>
</ul>
<h2 id="ZooKeeper的容灾能力"><a href="#ZooKeeper的容灾能力" class="headerlink" title="ZooKeeper的容灾能力"></a>ZooKeeper的容灾能力</h2><pre><code>(可容灾集群最低要求是3个节点)
</code></pre>
<ul>
<li>在集群运行过程中允许发生故障的节点数(最大:节点数-半-1)</li>
<li>如:集群只要1个节点，容灾能力为0<br>  集群只要2个节点，容灾能力为0<br>  集群只要3个节点，容灾能力为1<br>  集群只要4个节点，容灾能力为1</li>
<li>搭建集群时，尽量选择奇数台节点进行搭建</li>
</ul>
<h2 id="ZooKeeper的读特性"><a href="#ZooKeeper的读特性" class="headerlink" title="ZooKeeper的读特性"></a>ZooKeeper的读特性</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_6.png!vip" alt="读特性"></p>
<ol>
<li>Client发起读取请求</li>
<li>获取到数据(不管接收请求的是Leader节点还是Follower节点)</li>
</ol>
<h2 id="ZooKeeper的写特性"><a href="#ZooKeeper的写特性" class="headerlink" title="ZooKeeper的写特性"></a>ZooKeeper的写特性</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_7.png!vip" alt="写特性"></p>
<ol>
<li>Client发起写入请求 如果请求到的节点不是leader节点，follower会把请求转发给leader</li>
<li>leader接收到请求后会向所有节点发出询问是否可以接收写入</li>
<li>节点接收到询问请求,根据自身情况反馈是否可写入的信息给leader</li>
<li>leader接收到一半以上的节点可以写入，再执行写入</li>
<li>写入完成后反馈给client,如果Client请求的不是leader, leader把写 入状态反馈给follower,由follower反馈给client</li>
</ol>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><pre><code>数据处理(数据计算)
创建者:道格卡廷
出发点:搜索引擎--&gt;处理问题google: mapreduce论文MapReduce的特性:分布式计算
</code></pre>
<h2 id="MapReduce的特性-分布式计算"><a href="#MapReduce的特性-分布式计算" class="headerlink" title="MapReduce的特性:分布式计算"></a>MapReduce的特性:分布式计算</h2><ul>
<li>高度抽象的编程思想:编程人员只需要描述做什么，具体怎么做交由处理框架执行的</li>
<li>可扩展性:分布式、搭建在集群上的一-个处理组件</li>
<li>高容错性:处理任务时节点故障，迁移到其他节点执行任务MapReduce任务主要分为两大部分: map任务、 reduce任务</li>
</ul>
<h2 id="MapReduce任务"><a href="#MapReduce任务" class="headerlink" title="MapReduce任务"></a>MapReduce任务</h2><ul>
<li>reduce任务的处理数据来源是map任务的输出</li>
<li>map阶段:针对每个数据执行一个操作, 提取数据特征</li>
<li>reduce阶段:获取到多个map的输出，统一计 算处理,针对key统计汇总这个key对应的value</li>
</ul>
<h2 id="Map阶段详情"><a href="#Map阶段详情" class="headerlink" title="Map阶段详情"></a>Map阶段详情</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_8.png!vip" alt="Map阶段详情"></p>
<ol>
<li>数据从数据源获取后进行分片切分、执行map操作</li>
<li>分片会被存储在环形内存缓冲区( 当缓冲区达到80%会发生溢写)</li>
<li>把分片溢写到磁盘中，生成MOF文件</li>
<li>溢写过程中对数据执行</li>
</ol>
<h2 id="Map阶段详情-1"><a href="#Map阶段详情-1" class="headerlink" title="Map阶段详情"></a>Map阶段详情</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_9.png!vip" alt="Reduce阶段详情"></p>
<ol>
<li>把数据(MOF)从磁盘中加载到内存中</li>
<li>当数据量过大会执行归并，如果不多，直接跳过归并执行归约操作</li>
<li>执行完reduce操作之后，最终结果写入到HDFS</li>
</ol>
<h2 id="词频统计案例-单词计数WordCount"><a href="#词频统计案例-单词计数WordCount" class="headerlink" title="词频统计案例(单词计数WordCount)"></a>词频统计案例(单词计数WordCount)</h2><ol>
<li>数据源(很多英文句子或短语的一个文件)</li>
<li>提取出每个单词,统计单词出现的次数<br><img src="https://cdn.lovepp.xyz/blog/HCIA/img_10.png!vip" alt="词频统计案例"></li>
</ol>
<h2 id="MapReduce缺点"><a href="#MapReduce缺点" class="headerlink" title="MapReduce缺点"></a>MapReduce缺点</h2><ul>
<li>处理延迟性高</li>
<li>使用java语言编程map处理reduce处理</li>
<li>MapReduce处理任务需要使用资源</li>
</ul>
<h2 id="MapReduce-V1资源调度出现的问题"><a href="#MapReduce-V1资源调度出现的问题" class="headerlink" title="MapReduce V1资源调度出现的问题"></a>MapReduce V1资源调度出现的问题</h2><ul>
<li>如果发生问题，通知用户介入解决</li>
<li>没有区分任务调度和资源调度，都是MR的主节点在处理，主节点的整体工作压力非常大</li>
<li>因为资源没有单独隔离,容易出现资源抢占的问题</li>
</ul>
<h1 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h1><pre><code>资源调度管理服务---&gt; 可以协助其他组件应用协调管理资源，以及任务调度
</code></pre>
<h2 id="Yarn的系统架构"><a href="#Yarn的系统架构" class="headerlink" title="Yarn的系统架构"></a>Yarn的系统架构</h2><pre><code>在集群层面来说只有一个ResourceManager, 多个NodeManager
以程序执行层面来说，一个应用只有一-个AppMaster,多个Container
</code></pre>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_11.png!vip" alt="Yarn的系统架构"></p>
<ul>
<li>Client:客户端</li>
<li>ResourceManager (主节点) :负责资源管理,任务调度</li>
<li>NodeManager (从节点) :负责提供资源，实际任务执行</li>
<li>ApplicationMaster:特殊的Container, 管理同一应用的其他Container,以及实时关注任务执行状态,反馈给RM</li>
<li>Container:<code>资源的抽象</code>，被封装起来的资源，一个Container执行一个任务, 其他任务不能使用这个Container的资源</li>
</ul>
<h2 id="MapReduce-On-Yarn任务处理流程"><a href="#MapReduce-On-Yarn任务处理流程" class="headerlink" title="MapReduce On Yarn任务处理流程"></a><code>MapReduce On Yarn任务处理流程</code></h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_12.png!vip" alt="MapReduce On Yarn任务处理流程"></p>
<ol>
<li>Client向RM发起请求</li>
<li>RM(ApplicationManager)接收到请求后在NM中启动一-个AppMaster</li>
<li>AppMaster接收任务，根据任务向RM (ResourceScheduler) 申请资源</li>
<li>在NM中封装资源Container提供给AppMaster执行应用</li>
<li>执行过程中Container会实时反馈执行状态给AppMaster</li>
<li>AppMaster会反馈任务执行状态和自身状态给RM (ApplicationManager)</li>
<li>AppMaster将运行结果反馈给RM,然后向RM (ResourceScheduler) 申请释放资源</li>
<li>RM将任务情况反馈给Client</li>
</ol>
<p>Yarn搭建时支持主备配置，实现主备ResourceManager<br>AppMaster的容错(当-个AppMaster出现故障,任务管理会被迁移到新的AppMaster)</p>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_13.png!vip" alt="AppMaster的容错"></p>
<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><pre><code>HBase分布式列式NoSQL数据库，底层存储使用的是HDFS ,`没有数据类型，所有数据存储都是字节数组的形式byte[]`
创建者:道格卡廷
出发点:搜索引擎--&gt;提高数据读写速度--&gt; BigTable
</code></pre>
<h2 id="HBase的特性"><a href="#HBase的特性" class="headerlink" title="HBase的特性"></a>HBase的特性</h2><ul>
<li>可扩展性:可以通过添加节点的方式增加数据存储空间</li>
<li>高可靠性:底层使用HDFS,能够保证数据的可靠性，预写式日志保证内存中的数据不丢失</li>
<li>高性能:处理PB级别的数据</li>
<li>面向列: HBase数据存储是面向列的</li>
<li>可伸缩性:动态添加列(在添加数据的时候)- </li>
</ul>
<h2 id="面向列、面向行数据库的优缺点"><a href="#面向列、面向行数据库的优缺点" class="headerlink" title="面向列、面向行数据库的优缺点"></a>面向列、面向行数据库的优缺点</h2><ul>
<li>面向行:<br>  优点:能方便快捷的获取一一行记录<br>  缺点:在想要单独获取指定列数据的时候，会检索到其他无关列</li>
<li>面向列:<br>  优点:在检索单列数据时，不会出现无关列<br>  缺点:想要查询一条记录时，需要多次IO请求才能拼出一条记录</li>
</ul>
<h2 id="HBase和RDB-关系型数据库-的区别比较"><a href="#HBase和RDB-关系型数据库-的区别比较" class="headerlink" title="HBase和RDB (关系型数据库)的区别比较"></a>HBase和RDB (关系型数据库)的区别比较</h2><ul>
<li>数据索引: <br>HBase只有一 种索引(rowkey)，RDB中可以配置多个索引</li>
<li>数据维护: <br>HBase允许数据增删查,<code>不支持修改</code>，RDB中允许数据增删查改<br>HBase可以使用覆盖的方式写入数据以此实现数据修改的功能<br>可伸缩性: HBase可以在添加数据时动态添加列，RDB只能通过修改表的方式添加列<br>RDB (MySQL) 数据模型:数据库、表、行、列(字段)，单元格</li>
</ul>
<h2 id="HBase数据模型"><a href="#HBase数据模型" class="headerlink" title="HBase数据模型"></a>HBase数据模型</h2><pre><code>命名空间、表、行、列(组成列族)、单元格(可以存储多条记录)
</code></pre>
<ul>
<li>命名空间: hbase、 default. 自定义(在使用自定义的命名空间时都需要指定命名空间名称)</li>
<li>表:由行和列组成</li>
<li>行:有一个唯一表示行键(rowkey)</li>
<li>列:归属于某一个列族(<code>动态添加</code>)</li>
<li>列族:由一个或多个列组成(创建表时创建的，不能动态更改)</li>
<li>单元格:由行和列能确定-一个单元格，<code>一个单元格中可能存在多条记录(多版本记录，使用时间戳进行区分)</code></li>
</ul>
<h2 id="HBase的表结构"><a href="#HBase的表结构" class="headerlink" title="HBase的表结构"></a>HBase的表结构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_14.png!vip" alt="HBase的表结构"></p>
<pre><code>要找到行列对应的单元格值时，表行键,列族:列
默认情况下，只返回单元格中的最新记录，如果要返回多版本需要指定参数VERSIONS=&gt;3
</code></pre>
<h2 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title="HBase系统架构"></a>HBase系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_15.png!vip" alt="HBase系统架构"></p>
<ul>
<li>Client:用户可以通过Client连接到HBase,基本不与HMaster交互</li>
<li>ZooKeeper:监测HMaster的主备运行状态及主备切换，监测HRegionServer的状态，反馈给HMaster,<code>存储HBase元数据信息hbase:meta</code></li>
<li>Hmaster() ：管理维护HRegionServer列表，管理分配Region, Region负载均衡</li>
<li>HRegionServer：管理分配给它的Region，处理用户的读写请求</li>
<li>DFS Client: HBase连接到HDFS的接口</li>
</ul>
<p>一个HRegionserver中包含一个HLog， 多个HRegion</p>
<ul>
<li>HLog:预写式日志WAL,记录数据操作(数据写入之前必须先写入HLog)</li>
<li>Region:<code>分布式存储的最基本单位，刚开始一个Region存储一个表的内容随着数据增多</code>，Region会不断分裂<br>Store:一个Region中包含多个Store,<code>一个Store存储一个列族数据</code><br>MemStore (写缓存):一个Store包含一个MemStore <br>StoreFile (磁盘文件):一个Store中包含多个StoreFile<br>HFile (HDFS文件): 一个StoreFile添加头部信息转换成HFile,最终存储在HDFS中</li>
</ul>
<ul>
<li>数据写入关键流程:先写入HLog,然后才能写入MemStore,当MemStore达到溢出要求(128M) ,将数据刷写StoreFile中</li>
<li>数据读取关键流程:先读取MemStore,如果没有,再读取BlockCache (读缓存)，如果还是没有最终才读取StoreFile<br>BlockCache存储之前的用户查询过的数据，当MemStore和BlockCache中都没有数据， 需要从StoreFile<br>中读取数据时，读取完的数据会被加载到BlockCache中</li>
</ul>
<h2 id="Region拆分"><a href="#Region拆分" class="headerlink" title="Region拆分"></a>Region拆分</h2><ul>
<li>拆分原因:数据不断增加，region不断增大， region过大会影响数据读写速度</li>
<li>拆分条件:根据行键拆分，尽可能将同一个行键或相似的行键放在一个Region中</li>
<li>region拆分过程很快，接近瞬间,在拆分时实际还是请求的原文件,拆分结束之后会将原文件内容异步写入新文件,然后之后的请求被转移到新文件</li>
</ul>
<h2 id="Region定位"><a href="#Region定位" class="headerlink" title="Region定位"></a>Region定位</h2><p>  元数据信息存储在hbase:meta中,这个表信息被存储在zookeeper内存中通过元数据信息获取Region实际存储位置</p>
<h2 id="HRegionServerBR"><a href="#HRegionServerBR" class="headerlink" title="HRegionServerBR"></a>HRegionServerBR</h2><p>H RegionServer出现故障时</p>
<ol>
<li>zookeeper发现RegionServer故障，同时HMaster</li>
<li>HMaster获取故障的RegionServer上的HLog信息，根据与Region的对应关系对HLog进行拆分</li>
<li>把HLog存放在Region目录下，把Region重新迁移至其他的RegionServer上</li>
<li>其他的RegionServer接收到Region执行重新执行HLog内容</li>
</ol>
<h2 id="HLog的工作原理"><a href="#HLog的工作原理" class="headerlink" title="HLog的工作原理"></a>HLog的工作原理</h2><ul>
<li>HLog: WAL预写式日志，数据更新的操作都要先写入HLog中，才能写入MemStore<br><code>当MemStore被刷写到磁盘后，会向HLog中写入一条标记记录 (标记记录之前的所有数据都已经刷写到磁盘)</code></li>
<li>系统启动时，系统任务先扫描HLog, 检测是否有数据没有写入到磁盘中,如果有先执行写入MemStore,然后再刷写到磁盘，清空缓存,最后再为用户提供服务 <br>如果数据丢失，可以根据HLog重新执行恢复</li>
<li>一个RegionServer只有一-个HLog (共用一个HLog)<br>  优点:写入日志时不需要查找对应的Log,直接全部写入一个HLog<br>  缺点:如果RegionServer出现故障， 需要对HLog进行拆分</li>
</ul>
<h2 id="缓存刷写-把MemStore数据写入到StoreFile中"><a href="#缓存刷写-把MemStore数据写入到StoreFile中" class="headerlink" title="缓存刷写(把MemStore数据写入到StoreFile中)"></a>缓存刷写(把MemStore数据写入到StoreFile中)</h2><ul>
<li>当MemStore达到刷写条件，就会将内容刷写到StoreFile文件中</li>
<li>缓存的刷写是针对整个Region的，当一个MemStore达到刷写要求， 当前的Region下面的所有MemStore都会触发刷写</li>
<li>每次刷写都会生成一个新的StoreFile文件(每次的刷写内容都分别在一个新文件中)</li>
<li>刷写完成之后会在HLog中写入标记记录,并且清空缓存</li>
</ul>
<h2 id="StoreFile的合并"><a href="#StoreFile的合并" class="headerlink" title="StoreFile的合并"></a>StoreFile的合并</h2><pre><code>(刷写操作会出现大量的StoreFile,且部分StoreFile文件大小过小) 合并比较消耗资源,达到一定阈值才会执行
将多个的StoreFile小文件合并成一个大文件,如果StoreFile文件过大，再进行拆分(根据HDFS块进行拆分)
</code></pre>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_16.png!vip" alt="StoreFile的合并"></p>
<p>合并文件会进行筛选:如果本身的StoreFile就已经达到1 00M左右,这个StoreFile是不参与合并的</p>
<h2 id="HBase读取流程"><a href="#HBase读取流程" class="headerlink" title="HBase读取流程"></a>HBase读取流程</h2><ol>
<li>Client请求zookeeper获取hbase:meta表元数据信息，获取RegionServer信息</li>
<li>Client请求相对应的RegionServer</li>
<li>RegionServer接收到请求反馈数据给Client</li>
<li>关闭读取流</li>
</ol>
<h2 id="HBase写入流程"><a href="#HBase写入流程" class="headerlink" title="HBase写入流程"></a>HBase写入流程</h2><ol>
<li>Client请求的zookeeper,获取hbase:meta表信息,根据写入的行键获取对应的RegionServer信息</li>
<li>Client请求RegionServer发起写入请求</li>
<li>RegionServer接收到请求后将数据写入到行键对应的Region中.</li>
<li>RegionServer反馈写入状态给Client</li>
<li>关闭写入流</li>
</ol>
<h2 id="BloomFilter-布隆过滤器"><a href="#BloomFilter-布隆过滤器" class="headerlink" title="BloomFilter (布隆过滤器)"></a>BloomFilter (布隆过滤器)</h2><pre><code>判断数据是否存在，如果反馈结果为不存在，是可信的，如果反馈结果为存在，可能有误差
</code></pre>
<p>缩小数据违取范围<br><img src="https://cdn.lovepp.xyz/blog/HCIA/img_17.png!vip" alt="布隆过滤器"></p>
<p>在HBase中行键是以字典序进行排序<br><img src="https://cdn.lovepp.xyz/blog/HCIA/img_18.png!vip" alt="以字典序进行排序"></p>
<h2 id="HBase-Shell命令"><a href="#HBase-Shell命令" class="headerlink" title="HBase Shell命令"></a>HBase Shell命令</h2><pre><code class="sql">namespace:
    create_namespace &#39;名称&#39;
    list_namespace
    list_namespace_ tables &#39;ns1&#39;
    alter_namespace &#39;ns1 ,&#123;属性名称=&gt; &#39;属性值&#125;
    drop_ namespace &#39;ns1&#39; ---命名空间需要是空的

ddl:数据定义语言---&gt; 表层面的操作
    create &#39;表名&#39;,列族名1&#39;;列族2&#39;
    create &#39;表名,&#123;NAME= &gt; &#39;列族&#39; VERSIONS= &gt; 5&#125;,&#123;NAME= &gt;列族&#39; ,VERSIONS= &gt;5&#125;
    修改列族属性信息、添加列族: alter &#39;表名&#39;,&#123;NAME=&gt; &#39;列族&#39; ,VERSIONS=&gt;5&#125;--&gt;如果列族存在做修改，不存在做添加
    使用list可以查看所有的表:包含default命名空间和自定义命名空间中的表
    查看表信息: describe &#39;表名&#39;
    删除表: drop &#39;表名’--&gt; 禁用状态的表才 能进行删除
    禁用表: disable 表名&#39; /启用表: enable &#39;表名&#39;
    
dml:数据管理语言--&gt; 针对数据层面的操作
    添加数据: put &#39;表名，’行键&quot;,列族:列&quot;,值’--&gt; 默认使用的是系统时间戳
    删除数据: delete &#39;表名&quot;;行键’
    delete表名&#39;,行键&quot;，列族:列&#39;
    delete表名&#39;;行键&quot;,列族列,&#123;TIMESTEMP= &gt;&#39;235652&#39;&#125;
    清空表: truncate &#39;表名&#39;
    数据获取: get &#39;表名&#39;;行键’
    get &#39;表名&#39;行键&quot;;列族列
    get &#39;表名&#39;，&#39;行键&quot;;列族列,&#123;VERSIONS=&gt;3&#125;
    数据扫描: scan &#39;表名&#39;
    scan &#39;表名&quot;&#39;;行键&#39;;列族列,VERSIONS= &gt;3&#125;

snapshot:快照操作--&gt; 针对表创建快照，记录当前指定表的数据信息
    创建快照: snapshot &#39;表名&quot;，&#39;快照名称&#39;
    还原快照: resotre_ snapshot &#39;快照名&#39;
    克隆快照: clone_ snapshot ‘快照名;新表名&#39; ---&gt;把快照中的表内容还原到一-张新表上
    删除快照: delete snapshot &#39;快照名&#39;
</code></pre>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><pre><code>数据仓库，查询分析
</code></pre>
<h2 id="Hadoop生态圈"><a href="#Hadoop生态圈" class="headerlink" title="Hadoop生态圈"></a>Hadoop生态圈</h2><ul>
<li>HDFS存储、 HBase存储提供实时读写功能</li>
<li>MapReduce并行计算、Yarn资源管理和任务调度</li>
<li>ZooKeeper协助分布式应用管理服务</li>
<li>Hive底层使用的是MapReduce做计算，MapReduce的使用对编程人员要求比较高</li>
<li>可以执行SQL类的查询分析计算</li>
</ul>
<h2 id="Hive数据模型"><a href="#Hive数据模型" class="headerlink" title="Hive数据模型"></a>Hive数据模型</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_19.png!vip" alt="Hive数据模型"></p>
<ul>
<li>分区:根据字段值进行划分(指定分区字段,分区字段值相同的记录就存放在一一个分区中)<br>分区在物理上是一个文件夹<br>分区下还可以再有分区和桶<br>在创建表的时候可以指定分区字段<br>分区数量是不固定的</li>
<li>桶:根据值的哈希值进行求余放到对应的桶中<br>桶在物理.上是一-个文件<br>在创建表的时候可以指定有几个桶</li>
<li>表类型:托管表(内部表)、外部表、临时表<br>托管表(internal) :元数据和数据信息都是Hive在管理<br><code>删除时，元数据和数据都会被删除\</code><br>外部表(external) :元数据由Hive管理,但是数据可以提供给其他组件共享<br><code>删除时，只删除元数据，数据信息依旧保留\</code><br>临时表(temporary) :只在当前会话中生效，当会话结束表就会被自动删除</li>
</ul>
<h2 id="Hive数据仓库分层-逻辑分层"><a href="#Hive数据仓库分层-逻辑分层" class="headerlink" title="Hive数据仓库分层(逻辑分层)"></a>Hive数据仓库分层<code>(逻辑分层)</code></h2><ul>
<li>ODS (原数据层，操作数据层) :从数据源获取到的数据</li>
<li>DWD (数据明细层) :根据ODS做数据清洗得到的结果</li>
<li>DWS (数据服务层) :根据DWD进行汇总分析计算</li>
<li>ADS (应用服务层) :根据上层应用的业务需求将DWS数据再一次处理分析得到业务 需要的数据</li>
</ul>
<h2 id="Hive的分层处理的优势"><a href="#Hive的分层处理的优势" class="headerlink" title="Hive的分层处理的优势"></a>Hive的分层处理的优势</h2><ul>
<li>复杂问题简单化:将复杂问题分成多个流程，每个层面执行一-一个流程内容</li>
<li>减少重复开发:不要每次提供给上次应用数据时都要对数据进行清洗汇总操作</li>
<li>隔离原始数据:减少到原数据的依赖，避免因为原数据的原因，导致后续操作无法执行</li>
</ul>
<h2 id="Hive-SQL的使用"><a href="#Hive-SQL的使用" class="headerlink" title="Hive SQL的使用"></a>Hive SQL的使用</h2><pre><code class="sql">DDL:数据定义语言
    创建表: create table &#39;表名(字段类型,字段2类类型... .);
    create external table表名&#39;(字段类型,字段2类型....
    create temporary table &#39;表名&#39;(字段类型,字段2类型... .
    修改表: alter table表名&#39; rename to &#39;新表名;
    alter table &#39;表名&#39; addcolumns (字段类型);
    删除表: drop table &#39;表名&#39;;
    查询数据库中的所有表: show tables;
    查看表信息: describe table &#39;表名&#39;;
    
DML:数据管理语言
    添加数据:从文件中添加到表中
    load data inpath HDFS路径into table表名
    load data local inpath Linux路径into table表名
    load data local inpath Linux路径overwrite into table表
    
    从一个表添加到另-一个表中
    insert into table 表名 select * from 原表 where条件;
    from 原表 insert into table 表名 select * where 条件
    from 原表 insert overwrite table 表名 select 字段 where 条件
    从表中导出到文件中
    insert into directory HDFS路径 select * from表
    insert into local directory Linux 路径select * from 表
    export table 表 to HDFS路径
    
DQL:数据查询语言
    标准查询: select * from表名
    分组: select * from 表名 group by字段
    排序: select * from 表名 order by字段desc
    多表联合查询: select * from (select * from 表 a join 表b  on a.id= b.id)
    
创建表时的特殊操作
    分区: partitioned (字段类型)
    指定列分隔符: row format delimited fields terminated by &#39;分隔符&#39;
    指定外部表的存储路径: location 路径
    指定外部表的存储类型: stored as textfile
    指定字段加密: ROW FORMAT SERDE
    &#39;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#39; WITH SERDEPROPERTIES(
    &#39;column.encode.columns&#39;=&#39;字段1,字段
    2&#39;column.encode.classname&#39; =&#39;org apache.hadoop.hive.serde2.AESRewriter);
</code></pre>
<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="Spark特点"><a href="#Spark特点" class="headerlink" title="Spark特点"></a>Spark特点</h2><pre><code>轻快灵巧Spark的处理能力是MapReduce的30倍，处理能力不容易受到任务量增加的影响
</code></pre>
<p>轻:底层代码只有3万行，使用的函数式编程语言scala<br>快:处理速度快<br>灵:提供很多不同层面的处理功能<br>巧:巧妙的应用Hadoop平台</p>
<h2 id="RDD-分布式数据集、可分区的"><a href="#RDD-分布式数据集、可分区的" class="headerlink" title="RDD:分布式数据集、可分区的"></a>RDD:分布式数据集、可分区的</h2><ul>
<li>具有血统机制(RDD由父RDD执行操作之后产生)</li>
<li>如果子RDD丢失，RDD故障，重新执行父RDD就可以重新得到的子RDD</li>
<li>RDD默认存储在内存中，如果内存不足的时候，发生溢写</li>
<li>Spark节点会分配60%的内存用于做缓存，40%执行内存</li>
</ul>
<h2 id="依赖类型"><a href="#依赖类型" class="headerlink" title="依赖类型"></a>依赖类型</h2><pre><code>宽依赖、窄依赖
</code></pre>
<ul>
<li>窄依赖:父RDD的每个分区都只会被<code>一个</code>子RDD的分区所依赖</li>
<li>宽依赖:父RDD的每个分区可能会被<code>多个子RDD的分区所依赖</code></li>
</ul>
<h2 id="Stage划分"><a href="#Stage划分" class="headerlink" title="Stage划分"></a>Stage划分</h2><pre><code>遇到窄依赖就加入，宽依赖就断开，剩余的所有RDD被放在一个Stage中
</code></pre>
<h2 id="RDD操作类型"><a href="#RDD操作类型" class="headerlink" title="RDD操作类型"></a>RDD操作类型</h2><ul>
<li>创建操作:创建RDD用于接收数据结果</li>
<li>原始RDD:读取数据源获得的RDD (readFile(path))</li>
<li>转换得来:通过父RDD执行操作后得到的子RDD</li>
<li>控制操作:持久化RDD,可以持久化到内存或磁盘中,默认存在内存</li>
<li>转换操作:可对RDD执行的处理操作，转换操作是懒惰的，转换操作并不是立马执行，遇到行动操作才执行</li>
<li>行动操作:实际调用Spark执行(存储文件,数据输出等)</li>
</ul>
<ul>
<li>transformation算子在整个程序中 -&gt;声明转换操作,实际并没有执行</li>
<li>action算子时， 会从第一-个操作开始执行</li>
<li>DataFrame:属于一个DataSet实例， 不可变的弹性分布式数据集，存储数据时不止存储数据内容,存储数据对应结构信息及类型</li>
<li>DataSet:以对象的形式存储数据集，DataFrame= DataSet[Row]</li>
</ul>
<h2 id="RDD、DataFrame、-DataSet数据集的联系"><a href="#RDD、DataFrame、-DataSet数据集的联系" class="headerlink" title="RDD、DataFrame、 DataSet数据集的联系"></a>RDD、DataFrame、 DataSet数据集的联系</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_20.png!vip" alt="数据集的联系"></p>
<h2 id="Spark体系架构"><a href="#Spark体系架构" class="headerlink" title="Spark体系架构"></a>Spark体系架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_21.png!vip" alt="Spark体系架构"></p>
<ul>
<li>集群部署形式: <br>Standalone: spark自 己管理资源调度<br>Spark On Yarn:使用yarn做资源管理调度 <br>Mesos: AMR实验室开发的资源管理器，最适用于Spark的资源管理器</li>
<li>Spark Core:处理核心</li>
<li>Spark SQL:处理结构化数据，使用Hive元数据</li>
<li>Spark Streaming:实时流处理(实际微批处理) , 能够低延迟的计算反馈结果</li>
<li>MLLib:机器学习,根据历史数据进行建模，根据模型和提供的数据进行数据预测</li>
<li>GraphX:图计算,主要用于关系统计,关系查询</li>
<li>SparkR: R语言库,提供R语言接口，可以使用R语言操作Spark</li>
<li>Structured Streaming:流处理，将数据存入-个无边界表(新数据不断添加，旧数据不断移除)使用增量的方式获取表数据内容进行执行</li>
</ul>
<h1 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h1><pre><code>分布式流处理组件
</code></pre>
<h2 id="关键特性-实时响应，延迟性低"><a href="#关键特性-实时响应，延迟性低" class="headerlink" title="关键特性:实时响应，延迟性低"></a>关键特性:实时响应，延迟性低</h2><ul>
<li>数据不存储先执行(离线处理先存储数据然后再执行)</li>
<li>连续查询(程序运行后就不终止,除非系统故障导致的终止或者手动停止)</li>
<li>事件驱动:传入的数据信息触动任务处理</li>
</ul>
<h2 id="Streaming系统架构"><a href="#Streaming系统架构" class="headerlink" title="Streaming系统架构"></a>Streaming系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_22.png!vip" alt="Streaming系统架构"></p>
<ul>
<li>Client:客户端接口</li>
<li>Nimbus (主节点) :接收客户端的请求，管理Supervisor从节点，管理任务分配，编写任务书</li>
<li>Supervisor (从节点) :实行任务，管理worker</li>
<li>Worker (进程) :程序执行</li>
<li>Executor (线程) :每个Executor中默认执行一 一个Task</li>
<li>Task (任务) : Task分别对应每一 个Spout/Bolt组件的执行 </li>
<li>ZooKeeper:监控Nimbus主节点的状态，如果主节点故障切换备用节点<br>监控Supervisor从节点状态，如果从节点故障,通知Nimbus迁移任务，启动自动恢复<br>接收Nimbus任务书，将每个从节点的任务存放在每个Supervisor自己对应的目录中</li>
</ul>
<h2 id="Streaming任务架构"><a href="#Streaming任务架构" class="headerlink" title="Streaming任务架构"></a>Streaming任务架构</h2><ul>
<li>Topology:拓扑结构,封装任务执行流程</li>
<li>Spout:发送数据源的组件,接收第三方数据收集I具提供的数据发送到数据流</li>
<li>每个应用只有一个spout</li>
<li>Bolt:从数据流中获取数据,执行数据处理，如果当前bolt不是最后-个执行程序将结果放回数据流一个应用中可以有多个bolt</li>
<li>Tuple:数据流中的数据格式，组件之间数据传输的格式，元组中包含两个参数(id, stream)</li>
</ul>
<h2 id="Streaming执行任务"><a href="#Streaming执行任务" class="headerlink" title="Streaming执行任务"></a>Streaming执行任务</h2><ol>
<li>用户通过Client提交应用到Nimbus中</li>
<li>Nimbus接收到应用后，根据应用情况及当前集群的从节点情况编写任务书</li>
<li>将任务书.上传到ZooKeeper中</li>
<li>ZooKeeper接收到任务书后根据每个节点将对应的任务存放在节点对应的目录下</li>
<li>Supervisor周期性监测自己在ZooKeeper中的目录有没有新任务</li>
<li>Supervisor发现新任务，根据任务书内容从Nimbus中下载任务所需要的jar包</li>
<li>Supervisor执行任务,反馈执行状态给Nimbus .</li>
<li>Nimbus将任务状态反馈给Client</li>
</ol>
<h2 id="根据任务架构执行"><a href="#根据任务架构执行" class="headerlink" title="根据任务架构执行"></a>根据任务架构执行</h2><ol>
<li>获取拓扑结构</li>
<li>根据拓扑结构分别找到每一流程的处理单元</li>
<li>按照路程执行处理单元</li>
</ol>
<h2 id="消息传递语义"><a href="#消息传递语义" class="headerlink" title="消息传递语义"></a>消息传递语义</h2><ul>
<li>最多一次:数据发送只发送一次, 可靠性最低，吞吐量最大<br>  缺点:可能存在数据丢失的情况<br>  优点:数据一定不会被重复执行</li>
<li>最少一次:数据可能会发送多次，可靠性高，吞吐量较小<br>  优点:数据不会丢失<br>  缺点:数据可能会被重复执行</li>
<li>仅有一次(精准一次) :数据就发送一-次, 并且保证发送成功，可靠性高，吞吐量最低<br>  优点:数据不会丢失，且数据不被重复处理<br>  缺点:消耗的资源和时间较多</li>
</ul>
<h2 id="Ack机制-消息传输最少一次"><a href="#Ack机制-消息传输最少一次" class="headerlink" title="Ack机制(消息传输最少一次)"></a>Ack机制(消息传输最少一次)</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_23.png!vip" alt="Ack机制"></p>
<h1 id="Fink"><a href="#Fink" class="headerlink" title="Fink"></a>Fink</h1><pre><code>分布式实时计算引擎(流处理引擎)
</code></pre>
<h2 id="Flink-VS-Spark-Streaming"><a href="#Flink-VS-Spark-Streaming" class="headerlink" title="Flink VS Spark Streaming"></a>Flink VS Spark Streaming</h2><ul>
<li>Flink可以做流处理(侧重)也可以做批处理，底层引擎属于流处理引擎</li>
<li>通过流处理引擎模拟批处理形式实现的批处理</li>
<li>Spark可以做流处理也可以做批处理(侧重点)，底层弓|擎属于批处理引擎</li>
<li>通过批处理引擎,模拟流处理实现的流处理功能</li>
</ul>
<h2 id="Flink的关键特性"><a href="#Flink的关键特性" class="headerlink" title="Flink的关键特性"></a>Flink的关键特性</h2><pre><code>状态、时间、窗口、检查点
</code></pre>
<h2 id="Flink系统架构"><a href="#Flink系统架构" class="headerlink" title="Flink系统架构"></a>Flink系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_24.png!vip" alt="Flink系统架构"></p>
<ul>
<li>部署形式: Local (单机版部署)<br>  Cluster (Standalone: Flink集群自己管理资源调度<br>  Yarn:借助Yarn组件帮助管理协调资源和任务)<br>  Clound (云部署)</li>
<li>Flink核心模块: Runtime (不管是流处理还是批处理都是在Runtime中执行)</li>
<li>接口层: DataStream (流处理)和DataSet (批处理)</li>
<li>Table API &amp; SQL:处理结构化数据<br>```sql<br>Table API:将操作应用封装成方法<br>  select(“t_ demo “).where(“条件”)</li>
</ul>
<p>SQL:基于Table API使用，<br>    sqlQuery(“select * from t_ demo where条件”)</p>
<pre><code>
## 有界流和无界流
- 有界流:知道开始，知道结束，使用批处理处理有界流数据.
- 无界流:知道开始，不知道结束，使用流处理接口进行数据处理

## DataStream:用于存储数据的数据集，只能执行流处理操作
- 基于流处理运行环境获取到的数据

## DataSet:用来接收数据的数据集，只能执行批处理操作
- 基于批处理运行环境获取到的数据

`并不能在一个应用中同时接收流处理和批处理接口，以此实现流处理和批处理的共用`


## Flink运行流程

![Flink运行流程](https://cdn.lovepp.xyz/blog/HCIA/img_25.png!vip)

1. DataSource:接收数据输入，从数据源获取数据
2. Transformations:数据转换，数据处理过程
3. DataSink:将最终数据结果输出到指定位置(如HDFS、 HBase、 文件、数据库等)

## Flink程序运行流程
`1. 创建运行环境流处理/批处理`
2. 通过运行环境对象获取数据源数据(DataStream/DataSet)
3. 针对数据集进行数据转换
4. 将最终结果进行输出(批处理的print算子)
`5. 最后执行程序(行动算子) executor()`

## Flink运行程序
![Flink运行程序](https://cdn.lovepp.xyz/blog/HCIA/img_26.png!vip)

1. Client向JobManager发起请求
2. Client对任务进行优化等操作
3. JobManager分配任务给TaskManager
4. TaskManager接收到任务后执行任务
5. TaskManager反馈任务执行状态给JobManager
6. JobManager统一反馈给用户

- Flink Client:用户通过Client连接到JobManager
- JobManager (主节点) :接收用户请求，管理资源任务分配，管理从节点信息
- TaskManager (从节点) :接收任务处理任务，反馈给主节点
- Standalone部署:创建Task Slot: Flink的抽象资源

## Flink状态
    区别于其他组件的一-个特性，支持状态管理(中间结果状态)

## Fink窗口类型
- 滑动窗口: 窗口移动方式是平移,设定参数时需要设定窗口大小,滑动距离.窗口大小固定,可能会出现数据源重复和数据丢失的情况
- 滚动窗口: 窗口移动方式滚动,滚动距离就是窗口大小,设定窗口时只需要设定窗口大小.窗口大小固定,不会出现数据重复或者数据丢失的情况,会出现空窗口的情况
- 会话窗口: 由会话启动的窗口,设定过期时间,窗口代销不固定,运行时不会有丢失的数据,不会出现空窗口
- 时间窗口: 以时间为条件设定的窗口,`分别可以再分为滑动或滚动`
- 数量窗口: 由会话启动的窗口,设定过期时间,`分别可以再分为滑动或滚动`

## Fink的时间类型
- 时间类型: 事件发生的时间 
- 时间类型: 时间达到处理系统的时间
- 处理时间(默认): 时间被处理的时间
- 时间乱序问题: 事件被处理的顺序不是时间产生顺序
- 时间乱序原因: 数据受到数据传输影响


## Watermark(水位线/水印): 解决数据乱序问题
- 设定水位线时间,当水位线设定的时间时间也达到系统时,就会触发窗口执行
- 可设置水位线延迟,可允许窗口延迟触发\




## 对于延迟数据的处理方式
- 丢弃(默认): 当窗口已经被触发过,该窗口的数据达到也会被丢弃,不会被执行
- 可允许延迟: 设定可允许延迟时间,窗口已经被执行,但是输在可允许延迟时间达到,重新重发窗口的执行\
  `allowedLateness`(可延迟时间)
- 收集后做统一处理: 把所有的延迟数据收集起来,在程序最后做统一处理\
`OutputTag&lt;T&gt; lateOutputTag = new OutputTag //用于存放延迟数据的数据集`\
`.side0utputLateData(late0utputTag)`

## Flink容错性 (CheckPoint实现)
1. `CheckPoint:检查点，自动触发,当任务结束后会自动删除`
    - 保存当前任务状态，周期性触发,默认情况下不启动检查点
    - 在启动检查点时就可以设定周期时间，单位ms: .enableCheckPointing(10000)
    - 修改消息传输语义(默认情况仅有一次): .setCheckPointMode(CheckPointMode.AT_LEAST_ONCE)
    - 快照超时时间:防止一个问题快照影响大量快照创建堆积: .setCheckpointingTimeout(60000)
    - 可以设定检查点之间的最小间隔时间
    - 可以设定最大并行执行数量
    - 设定外部检查点:可以把检查点信息存储于在外部系统中，不会因为Flink系统问题受到影响
2. SavePoint:保存点，底层CheckPoint, 手动触发,任务结束后也依旧保留

## 状态保存
内存:默认，state和checkpoint都存储在内存，只是用本地测试
文件系统: state在内存， checkpoint在文件系统中
数据库: state存储在内置数据库中，checkpoint在文件系统中，针对大量数据任务处理的场景

# 转载连接
## ![Chenci&#39;s blog：华为HCIA](https://chencicici.github.io/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/)
</code></pre>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>HCIA</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
</search>
