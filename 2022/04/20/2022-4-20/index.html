<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
       
      <meta name="keywords" content="博客，IT，Python，编程" />
       
      <meta name="description" content="一个菜鸡的日常记录" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>华为HCIA（Big Data）培训记录 |  UodRad的博客</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="http://uodrad-image.test.upcdn.net/blog/avatar.png" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link rel="alternate" href="/atom.xml" title="UodRad的博客" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-2022-4-20"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  华为HCIA（Big Data）培训记录
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/04/20/2022-4-20/" class="article-date">
  <time datetime="2022-04-20T06:28:15.000Z" itemprop="datePublished">2022-04-20</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">9.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">33 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="大数据概述-amp-解决办法"><a href="#大数据概述-amp-解决办法" class="headerlink" title="大数据概述&amp;解决办法"></a>大数据概述&amp;解决办法</h1><h2 id="大数据的特征（5v-1c）"><a href="#大数据的特征（5v-1c）" class="headerlink" title="大数据的特征（5v+1c）"></a>大数据的特征（5v+1c）</h2><ul>
<li>大量：数据量巨大，MB,GB,TB,PB</li>
<li>多样：数据类型多样，数据来源多样 数据来源：服务器日志、网站浏览信息、社交<br>结构化数据：表格数据 平台、摄像头信息<br>半结构化数据：网页html、xml<br>非结构化数据：视频、音频、图片、文字</li>
<li>高速：数据产生速度快、数据处理速度快</li>
<li>价值：价值密度低</li>
<li>准确：数据真实性</li>
<li>复杂：数据产生速度快、数据的类型多样等特征，导致做数据处理时处理过程变得很复杂</li>
</ul>
<span id="more"></span>

<h2 id="大数据处理流程"><a href="#大数据处理流程" class="headerlink" title="大数据处理流程"></a>大数据处理流程</h2><p>数据采集-&gt;数据预处理-&gt;数据存储-&gt;分析挖掘-&gt;数据可视化</p>
<h3 id="大数据任务类型"><a href="#大数据任务类型" class="headerlink" title="大数据任务类型"></a>大数据任务类型</h3><ul>
<li>IO密集型任务：大量输入输出请求的任务IO资源</li>
<li>计算密集型任务：有大量的计算要求，CPU资源</li>
<li>数据密集型任务：数据处理，并发数据处理</li>
</ul>
<h2 id="大数据的计算类型（数据处理类型）"><a href="#大数据的计算类型（数据处理类型）" class="headerlink" title="大数据的计算类型（数据处理类型）"></a>大数据的计算类型（数据处理类型）</h2><ul>
<li>批处理：一次处理一批量数据，处理的数据量大，但是延迟性高</li>
<li>流处理：一次处理一条数据，处理的数据量小，但是延迟性低</li>
<li>图处理：以图的形式展示数据，进行处理</li>
<li>查询分析计算：检索功能</li>
</ul>
<h2 id="大数据解决方案"><a href="#大数据解决方案" class="headerlink" title="大数据解决方案"></a>大数据解决方案</h2><p>Fusioninsight HD:部署在x86架构上<br>BigData pro:部署在ARM架构上<br>MapReduce Server（MRS）:部署华为云服务上</p>
<ul>
<li>高性能：支持自我研发的存储系统CarbonData</li>
<li>易运维：提供了可视化的管理界面</li>
<li>高安全：使用Kerborse &amp; Ldap实现认证管理和权限管理</li>
<li>低成本：按需购买，自定义配置底层架构性能</li>
</ul>
<h1 id="HDFS分布式文件系统"><a href="#HDFS分布式文件系统" class="headerlink" title="HDFS分布式文件系统"></a>HDFS分布式文件系统</h1><h2 id="HDFS-Hadoop分布式文件系统"><a href="#HDFS-Hadoop分布式文件系统" class="headerlink" title="HDFS (Hadoop分布式文件系统)"></a>HDFS (Hadoop分布式文件系统)</h2><ul>
<li>创建人:道格卡廷</li>
<li>起始原因:开发一个搜索引擎–&gt;存储问题(大量数据的存储)</li>
<li>google论文: GFS - google自身的分布式文件系统 <code>闭源</code></li>
</ul>
<h2 id="HDFS特性"><a href="#HDFS特性" class="headerlink" title="HDFS特性"></a>HDFS特性</h2><p>理论上HDFS存储可以无限扩展</p>
<ul>
<li>分布式:把多节点的存储系统结合为一一个整体对外提供服务(提高存储能力)</li>
<li>容错性:针对每个数据存储备份(默认3份)，备份存储分别存在不同的位置，如果备份或者数据有丢失，会再进行备份，保持一直都是3份</li>
<li>按块存储:块大小默认128M, 一个文件可以存储在多个块,<code>但是一个块只存储一个文件</code> <br><code>好处:数据丢失针对丢失的数据所属的块，只恢复当前块就可以</code></li>
<li>元数据:记录文件存储在哪些块,块存储在哪里等信息 <br>每个块都有一个元数据信息，并且元数据的大小是固定的150K</li>
</ul>
<h2 id="HDFS适用场景"><a href="#HDFS适用场景" class="headerlink" title="HDFS适用场景"></a>HDFS适用场景</h2><ul>
<li>可以做大文件</li>
<li>可以协助离线处理或批处理</li>
<li>流式数据访问机制</li>
</ul>
<h2 id="HDFS不适合做什么"><a href="#HDFS不适合做什么" class="headerlink" title="HDFS不适合做什么"></a>HDFS不适合做什么</h2><ul>
<li>不适合大量小文件存储</li>
<li>不适合做实时场景</li>
<li>不适合随机读写，可以做追加写</li>
</ul>
<h2 id="HDFS为什么不适合大量小文件存储"><a href="#HDFS为什么不适合大量小文件存储" class="headerlink" title="HDFS为什么不适合大量小文件存储"></a><code>HDFS为什么不适合大量小文件存储</code></h2><pre><code>(例: 10个文件，每个文件大小为20M)
</code></pre>
<ol>
<li>10个文件需要使用10个块，并且每个块只是用了20M空间—&gt; 存储空间浪费</li>
<li>有10个元数据，元数据150K</li>
<li>寻址时间增长</li>
</ol>
<p>不适合随机读写，可以做追加写</p>
<h2 id="HDFS系统架构"><a href="#HDFS系统架构" class="headerlink" title="HDFS系统架构"></a>HDFS系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img.png!vip" alt="HDFS系统架构"></p>
<ul>
<li>Client (客户端) :用户接口，用户通过Client连接到组件</li>
<li>NameNode (名称节点，主节点) :管理DataNode,并且接收用户请求,分发任务，存储元数据信息</li>
<li>DataNode (数据节点，从节点) :实际处理用户请求，维护自己的Block和实际存储位置映射关系</li>
<li>Block (块) : 数据存储</li>
</ul>
<h2 id="HDFS单NameNode的问题"><a href="#HDFS单NameNode的问题" class="headerlink" title="HDFS单NameNode的问题"></a>HDFS单NameNode的问题</h2><ul>
<li>单名称节点故障:整个集群都无法使用—&gt;HA(主备配置)</li>
<li>单名称节点性能瓶颈问题:并发处理的任务量有限—-&gt;联邦机制</li>
</ul>
<h2 id="HDFS-HA特性-主备配置"><a href="#HDFS-HA特性-主备配置" class="headerlink" title="HDFS HA特性(主备配置)"></a>HDFS HA特性(主备配置)</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_1.png!vip" alt="HA特性"></p>
<ul>
<li>active节点:对外提供服务</li>
<li>standby节点:不断备份active节点的数据，<code>当active宕机,standby会成为新的active</code></li>
<li>zookeeper监测主节点的状态，一旦发现故障，zookeeper就通知备用节点成为新的主节点</li>
</ul>
<h2 id="HDFS的联邦机制"><a href="#HDFS的联邦机制" class="headerlink" title="HDFS的联邦机制"></a>HDFS的联邦机制</h2><pre><code>各个NN之间是相互隔离的，维护自己的命名空间
</code></pre>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_2.png!vip" alt="联邦机制"></p>
<h2 id="HDFS元数据持久化-主备同步"><a href="#HDFS元数据持久化-主备同步" class="headerlink" title="HDFS元数据持久化(主备同步)"></a>HDFS元数据持久化(主备同步)</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_3.png!vip" alt="元数据持久化"></p>
<ol>
<li>备节点会通知主节点新建一个Editlog.new文件， 从这之后的操作都记录在.new文件中</li>
<li>备节点从主节点拷贝Editlog、Fsimage文件(只有第一 次需要 下载Fsimage,后续同步使用本地的)</li>
<li>将两个文件进行合并，生成Fsimage.ckpt文件</li>
<li>备节点将Fsimage.ckpt上传到主节点上</li>
<li>主节点接收到Fsimage.ckpt恢复成Fsimage</li>
<li>把Editlog.new重命名Editlog</li>
</ol>
<h2 id="HDFS副本机制-3份"><a href="#HDFS副本机制-3份" class="headerlink" title="HDFS副本机制 (3份)"></a>HDFS副本机制 (3份)</h2><ul>
<li>存储副本规则: </li>
</ul>
<ol>
<li>第一份副本存放在同一节点中(传输最快,但是如果节点故障，副本也会丢失)</li>
<li>第二份副本存放在同一机架的不同节点上(如果整个机架故障，副本也会丢失)</li>
<li>第三分副本存放在不同机架的其他节点上</li>
</ol>
<ul>
<li>副本距离公式:<code>优先选择的是距离小的</code></li>
</ul>
<ol>
<li>同节点的距离为0</li>
<li>同一机架不同节点的距离为2</li>
<li>不同机架的节点距离为4</li>
</ol>
<h2 id="HDFS读取流程"><a href="#HDFS读取流程" class="headerlink" title="HDFS读取流程"></a>HDFS读取流程</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_4.png!vip" alt="读取流程"></p>
<ol>
<li>Client向NameNode发起读取请求</li>
<li>NameNode接收到请求，反馈对应的元数据信息给Client</li>
<li>Client接收到反馈请求对应的DataNode <code>(如果Client本地有数据，优先从本地读取)</code></li>
<li>DataNode接收到请求，反馈数据内容给Client</li>
<li>关闭读取流</li>
</ol>
<h2 id="HDFS写入流程"><a href="#HDFS写入流程" class="headerlink" title="HDFS写入流程"></a>HDFS写入流程</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_5.png!vip" alt="写入流程"></p>
<ol>
<li>Client向NameNode发出写入请求</li>
<li>NameNode接收到请求后生成该文件的元数据信息，反馈DataNode信息给Client</li>
<li>Client接收到DataNode信息之后，请求相对应的DataNode</li>
<li>Client提交文件写入到对应的DataNode</li>
<li>DataNode接收到写入请求，执行写入</li>
<li>Client写入第一-个节点后，由第一个节点写入第二个节点，第二个节点写入第三个节点</li>
<li>写入完成后反馈元数据信息给Client</li>
<li>关闭读取流，NameNode更新元数据信息</li>
</ol>
<h1 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h1><pre><code>分布式服务应用，可以帮助其他分布式组件协调管理集群
</code></pre>
<h2 id="ZooKeeper的特性"><a href="#ZooKeeper的特性" class="headerlink" title="ZooKeeper的特性"></a>ZooKeeper的特性</h2><ul>
<li>分布式服务, ZooKeeper集群中有一半以上的节点存活集群才能正常运行</li>
<li>最终一致性:所有的节点对外提供的是同一个视图</li>
<li>实时性:实时获取、实时反馈应用状态</li>
<li>可靠性: 一条数据被-个节点接收到，就会被其他节点也接收</li>
<li>等待无关性:慢的或者失效的client请求，不会影响到其他客户端请求</li>
<li>原子性:最终状态只有成功或者失败</li>
</ul>
<h2 id="ZooKeeper集群主从选举-主备切换"><a href="#ZooKeeper集群主从选举-主备切换" class="headerlink" title="ZooKeeper集群主从选举/主备切换"></a>ZooKeeper集群主从选举/主备切换</h2><ul>
<li>选举: zookeeper内部投票选举,当节点得到一半以上的票数,它就会称为Leader,其他的节点都是Follower</li>
<li>主备切换:当leader出现故障,从其他的follower中重新选举新的leader</li>
</ul>
<h2 id="ZooKeeper的容灾能力"><a href="#ZooKeeper的容灾能力" class="headerlink" title="ZooKeeper的容灾能力"></a>ZooKeeper的容灾能力</h2><pre><code>(可容灾集群最低要求是3个节点)
</code></pre>
<ul>
<li>在集群运行过程中允许发生故障的节点数(最大:节点数-半-1)</li>
<li>如:集群只要1个节点，容灾能力为0<br>  集群只要2个节点，容灾能力为0<br>  集群只要3个节点，容灾能力为1<br>  集群只要4个节点，容灾能力为1</li>
<li>搭建集群时，尽量选择奇数台节点进行搭建</li>
</ul>
<h2 id="ZooKeeper的读特性"><a href="#ZooKeeper的读特性" class="headerlink" title="ZooKeeper的读特性"></a>ZooKeeper的读特性</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_6.png!vip" alt="读特性"></p>
<ol>
<li>Client发起读取请求</li>
<li>获取到数据(不管接收请求的是Leader节点还是Follower节点)</li>
</ol>
<h2 id="ZooKeeper的写特性"><a href="#ZooKeeper的写特性" class="headerlink" title="ZooKeeper的写特性"></a>ZooKeeper的写特性</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_7.png!vip" alt="写特性"></p>
<ol>
<li>Client发起写入请求 如果请求到的节点不是leader节点，follower会把请求转发给leader</li>
<li>leader接收到请求后会向所有节点发出询问是否可以接收写入</li>
<li>节点接收到询问请求,根据自身情况反馈是否可写入的信息给leader</li>
<li>leader接收到一半以上的节点可以写入，再执行写入</li>
<li>写入完成后反馈给client,如果Client请求的不是leader, leader把写 入状态反馈给follower,由follower反馈给client</li>
</ol>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><pre><code>数据处理(数据计算)
创建者:道格卡廷
出发点:搜索引擎--&gt;处理问题google: mapreduce论文MapReduce的特性:分布式计算
</code></pre>
<h2 id="MapReduce的特性-分布式计算"><a href="#MapReduce的特性-分布式计算" class="headerlink" title="MapReduce的特性:分布式计算"></a>MapReduce的特性:分布式计算</h2><ul>
<li>高度抽象的编程思想:编程人员只需要描述做什么，具体怎么做交由处理框架执行的</li>
<li>可扩展性:分布式、搭建在集群上的一-个处理组件</li>
<li>高容错性:处理任务时节点故障，迁移到其他节点执行任务MapReduce任务主要分为两大部分: map任务、 reduce任务</li>
</ul>
<h2 id="MapReduce任务"><a href="#MapReduce任务" class="headerlink" title="MapReduce任务"></a>MapReduce任务</h2><ul>
<li>reduce任务的处理数据来源是map任务的输出</li>
<li>map阶段:针对每个数据执行一个操作, 提取数据特征</li>
<li>reduce阶段:获取到多个map的输出，统一计 算处理,针对key统计汇总这个key对应的value</li>
</ul>
<h2 id="Map阶段详情"><a href="#Map阶段详情" class="headerlink" title="Map阶段详情"></a>Map阶段详情</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_8.png!vip" alt="Map阶段详情"></p>
<ol>
<li>数据从数据源获取后进行分片切分、执行map操作</li>
<li>分片会被存储在环形内存缓冲区( 当缓冲区达到80%会发生溢写)</li>
<li>把分片溢写到磁盘中，生成MOF文件</li>
<li>溢写过程中对数据执行</li>
</ol>
<h2 id="Map阶段详情-1"><a href="#Map阶段详情-1" class="headerlink" title="Map阶段详情"></a>Map阶段详情</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_9.png!vip" alt="Reduce阶段详情"></p>
<ol>
<li>把数据(MOF)从磁盘中加载到内存中</li>
<li>当数据量过大会执行归并，如果不多，直接跳过归并执行归约操作</li>
<li>执行完reduce操作之后，最终结果写入到HDFS</li>
</ol>
<h2 id="词频统计案例-单词计数WordCount"><a href="#词频统计案例-单词计数WordCount" class="headerlink" title="词频统计案例(单词计数WordCount)"></a>词频统计案例(单词计数WordCount)</h2><ol>
<li>数据源(很多英文句子或短语的一个文件)</li>
<li>提取出每个单词,统计单词出现的次数<br><img src="https://cdn.lovepp.xyz/blog/HCIA/img_10.png!vip" alt="词频统计案例"></li>
</ol>
<h2 id="MapReduce缺点"><a href="#MapReduce缺点" class="headerlink" title="MapReduce缺点"></a>MapReduce缺点</h2><ul>
<li>处理延迟性高</li>
<li>使用java语言编程map处理reduce处理</li>
<li>MapReduce处理任务需要使用资源</li>
</ul>
<h2 id="MapReduce-V1资源调度出现的问题"><a href="#MapReduce-V1资源调度出现的问题" class="headerlink" title="MapReduce V1资源调度出现的问题"></a>MapReduce V1资源调度出现的问题</h2><ul>
<li>如果发生问题，通知用户介入解决</li>
<li>没有区分任务调度和资源调度，都是MR的主节点在处理，主节点的整体工作压力非常大</li>
<li>因为资源没有单独隔离,容易出现资源抢占的问题</li>
</ul>
<h1 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h1><pre><code>资源调度管理服务---&gt; 可以协助其他组件应用协调管理资源，以及任务调度
</code></pre>
<h2 id="Yarn的系统架构"><a href="#Yarn的系统架构" class="headerlink" title="Yarn的系统架构"></a>Yarn的系统架构</h2><pre><code>在集群层面来说只有一个ResourceManager, 多个NodeManager
以程序执行层面来说，一个应用只有一-个AppMaster,多个Container
</code></pre>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_11.png!vip" alt="Yarn的系统架构"></p>
<ul>
<li>Client:客户端</li>
<li>ResourceManager (主节点) :负责资源管理,任务调度</li>
<li>NodeManager (从节点) :负责提供资源，实际任务执行</li>
<li>ApplicationMaster:特殊的Container, 管理同一应用的其他Container,以及实时关注任务执行状态,反馈给RM</li>
<li>Container:<code>资源的抽象</code>，被封装起来的资源，一个Container执行一个任务, 其他任务不能使用这个Container的资源</li>
</ul>
<h2 id="MapReduce-On-Yarn任务处理流程"><a href="#MapReduce-On-Yarn任务处理流程" class="headerlink" title="MapReduce On Yarn任务处理流程"></a><code>MapReduce On Yarn任务处理流程</code></h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_12.png!vip" alt="MapReduce On Yarn任务处理流程"></p>
<ol>
<li>Client向RM发起请求</li>
<li>RM(ApplicationManager)接收到请求后在NM中启动一-个AppMaster</li>
<li>AppMaster接收任务，根据任务向RM (ResourceScheduler) 申请资源</li>
<li>在NM中封装资源Container提供给AppMaster执行应用</li>
<li>执行过程中Container会实时反馈执行状态给AppMaster</li>
<li>AppMaster会反馈任务执行状态和自身状态给RM (ApplicationManager)</li>
<li>AppMaster将运行结果反馈给RM,然后向RM (ResourceScheduler) 申请释放资源</li>
<li>RM将任务情况反馈给Client</li>
</ol>
<p>Yarn搭建时支持主备配置，实现主备ResourceManager<br>AppMaster的容错(当-个AppMaster出现故障,任务管理会被迁移到新的AppMaster)</p>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_13.png!vip" alt="AppMaster的容错"></p>
<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><pre><code>HBase分布式列式NoSQL数据库，底层存储使用的是HDFS ,`没有数据类型，所有数据存储都是字节数组的形式byte[]`
创建者:道格卡廷
出发点:搜索引擎--&gt;提高数据读写速度--&gt; BigTable
</code></pre>
<h2 id="HBase的特性"><a href="#HBase的特性" class="headerlink" title="HBase的特性"></a>HBase的特性</h2><ul>
<li>可扩展性:可以通过添加节点的方式增加数据存储空间</li>
<li>高可靠性:底层使用HDFS,能够保证数据的可靠性，预写式日志保证内存中的数据不丢失</li>
<li>高性能:处理PB级别的数据</li>
<li>面向列: HBase数据存储是面向列的</li>
<li>可伸缩性:动态添加列(在添加数据的时候)- </li>
</ul>
<h2 id="面向列、面向行数据库的优缺点"><a href="#面向列、面向行数据库的优缺点" class="headerlink" title="面向列、面向行数据库的优缺点"></a>面向列、面向行数据库的优缺点</h2><ul>
<li>面向行:<br>  优点:能方便快捷的获取一一行记录<br>  缺点:在想要单独获取指定列数据的时候，会检索到其他无关列</li>
<li>面向列:<br>  优点:在检索单列数据时，不会出现无关列<br>  缺点:想要查询一条记录时，需要多次IO请求才能拼出一条记录</li>
</ul>
<h2 id="HBase和RDB-关系型数据库-的区别比较"><a href="#HBase和RDB-关系型数据库-的区别比较" class="headerlink" title="HBase和RDB (关系型数据库)的区别比较"></a>HBase和RDB (关系型数据库)的区别比较</h2><ul>
<li>数据索引: <br>HBase只有一 种索引(rowkey)，RDB中可以配置多个索引</li>
<li>数据维护: <br>HBase允许数据增删查,<code>不支持修改</code>，RDB中允许数据增删查改<br>HBase可以使用覆盖的方式写入数据以此实现数据修改的功能<br>可伸缩性: HBase可以在添加数据时动态添加列，RDB只能通过修改表的方式添加列<br>RDB (MySQL) 数据模型:数据库、表、行、列(字段)，单元格</li>
</ul>
<h2 id="HBase数据模型"><a href="#HBase数据模型" class="headerlink" title="HBase数据模型"></a>HBase数据模型</h2><pre><code>命名空间、表、行、列(组成列族)、单元格(可以存储多条记录)
</code></pre>
<ul>
<li>命名空间: hbase、 default. 自定义(在使用自定义的命名空间时都需要指定命名空间名称)</li>
<li>表:由行和列组成</li>
<li>行:有一个唯一表示行键(rowkey)</li>
<li>列:归属于某一个列族(<code>动态添加</code>)</li>
<li>列族:由一个或多个列组成(创建表时创建的，不能动态更改)</li>
<li>单元格:由行和列能确定-一个单元格，<code>一个单元格中可能存在多条记录(多版本记录，使用时间戳进行区分)</code></li>
</ul>
<h2 id="HBase的表结构"><a href="#HBase的表结构" class="headerlink" title="HBase的表结构"></a>HBase的表结构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_14.png!vip" alt="HBase的表结构"></p>
<pre><code>要找到行列对应的单元格值时，表行键,列族:列
默认情况下，只返回单元格中的最新记录，如果要返回多版本需要指定参数VERSIONS=&gt;3
</code></pre>
<h2 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title="HBase系统架构"></a>HBase系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_15.png!vip" alt="HBase系统架构"></p>
<ul>
<li>Client:用户可以通过Client连接到HBase,基本不与HMaster交互</li>
<li>ZooKeeper:监测HMaster的主备运行状态及主备切换，监测HRegionServer的状态，反馈给HMaster,<code>存储HBase元数据信息hbase:meta</code></li>
<li>Hmaster() ：管理维护HRegionServer列表，管理分配Region, Region负载均衡</li>
<li>HRegionServer：管理分配给它的Region，处理用户的读写请求</li>
<li>DFS Client: HBase连接到HDFS的接口</li>
</ul>
<p>一个HRegionserver中包含一个HLog， 多个HRegion</p>
<ul>
<li>HLog:预写式日志WAL,记录数据操作(数据写入之前必须先写入HLog)</li>
<li>Region:<code>分布式存储的最基本单位，刚开始一个Region存储一个表的内容随着数据增多</code>，Region会不断分裂<br>Store:一个Region中包含多个Store,<code>一个Store存储一个列族数据</code><br>MemStore (写缓存):一个Store包含一个MemStore <br>StoreFile (磁盘文件):一个Store中包含多个StoreFile<br>HFile (HDFS文件): 一个StoreFile添加头部信息转换成HFile,最终存储在HDFS中</li>
</ul>
<ul>
<li>数据写入关键流程:先写入HLog,然后才能写入MemStore,当MemStore达到溢出要求(128M) ,将数据刷写StoreFile中</li>
<li>数据读取关键流程:先读取MemStore,如果没有,再读取BlockCache (读缓存)，如果还是没有最终才读取StoreFile<br>BlockCache存储之前的用户查询过的数据，当MemStore和BlockCache中都没有数据， 需要从StoreFile<br>中读取数据时，读取完的数据会被加载到BlockCache中</li>
</ul>
<h2 id="Region拆分"><a href="#Region拆分" class="headerlink" title="Region拆分"></a>Region拆分</h2><ul>
<li>拆分原因:数据不断增加，region不断增大， region过大会影响数据读写速度</li>
<li>拆分条件:根据行键拆分，尽可能将同一个行键或相似的行键放在一个Region中</li>
<li>region拆分过程很快，接近瞬间,在拆分时实际还是请求的原文件,拆分结束之后会将原文件内容异步写入新文件,然后之后的请求被转移到新文件</li>
</ul>
<h2 id="Region定位"><a href="#Region定位" class="headerlink" title="Region定位"></a>Region定位</h2><p>  元数据信息存储在hbase:meta中,这个表信息被存储在zookeeper内存中通过元数据信息获取Region实际存储位置</p>
<h2 id="HRegionServerBR"><a href="#HRegionServerBR" class="headerlink" title="HRegionServerBR"></a>HRegionServerBR</h2><p>H RegionServer出现故障时</p>
<ol>
<li>zookeeper发现RegionServer故障，同时HMaster</li>
<li>HMaster获取故障的RegionServer上的HLog信息，根据与Region的对应关系对HLog进行拆分</li>
<li>把HLog存放在Region目录下，把Region重新迁移至其他的RegionServer上</li>
<li>其他的RegionServer接收到Region执行重新执行HLog内容</li>
</ol>
<h2 id="HLog的工作原理"><a href="#HLog的工作原理" class="headerlink" title="HLog的工作原理"></a>HLog的工作原理</h2><ul>
<li>HLog: WAL预写式日志，数据更新的操作都要先写入HLog中，才能写入MemStore<br><code>当MemStore被刷写到磁盘后，会向HLog中写入一条标记记录 (标记记录之前的所有数据都已经刷写到磁盘)</code></li>
<li>系统启动时，系统任务先扫描HLog, 检测是否有数据没有写入到磁盘中,如果有先执行写入MemStore,然后再刷写到磁盘，清空缓存,最后再为用户提供服务 <br>如果数据丢失，可以根据HLog重新执行恢复</li>
<li>一个RegionServer只有一-个HLog (共用一个HLog)<br>  优点:写入日志时不需要查找对应的Log,直接全部写入一个HLog<br>  缺点:如果RegionServer出现故障， 需要对HLog进行拆分</li>
</ul>
<h2 id="缓存刷写-把MemStore数据写入到StoreFile中"><a href="#缓存刷写-把MemStore数据写入到StoreFile中" class="headerlink" title="缓存刷写(把MemStore数据写入到StoreFile中)"></a>缓存刷写(把MemStore数据写入到StoreFile中)</h2><ul>
<li>当MemStore达到刷写条件，就会将内容刷写到StoreFile文件中</li>
<li>缓存的刷写是针对整个Region的，当一个MemStore达到刷写要求， 当前的Region下面的所有MemStore都会触发刷写</li>
<li>每次刷写都会生成一个新的StoreFile文件(每次的刷写内容都分别在一个新文件中)</li>
<li>刷写完成之后会在HLog中写入标记记录,并且清空缓存</li>
</ul>
<h2 id="StoreFile的合并"><a href="#StoreFile的合并" class="headerlink" title="StoreFile的合并"></a>StoreFile的合并</h2><pre><code>(刷写操作会出现大量的StoreFile,且部分StoreFile文件大小过小) 合并比较消耗资源,达到一定阈值才会执行
将多个的StoreFile小文件合并成一个大文件,如果StoreFile文件过大，再进行拆分(根据HDFS块进行拆分)
</code></pre>
<p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_16.png!vip" alt="StoreFile的合并"></p>
<p>合并文件会进行筛选:如果本身的StoreFile就已经达到1 00M左右,这个StoreFile是不参与合并的</p>
<h2 id="HBase读取流程"><a href="#HBase读取流程" class="headerlink" title="HBase读取流程"></a>HBase读取流程</h2><ol>
<li>Client请求zookeeper获取hbase:meta表元数据信息，获取RegionServer信息</li>
<li>Client请求相对应的RegionServer</li>
<li>RegionServer接收到请求反馈数据给Client</li>
<li>关闭读取流</li>
</ol>
<h2 id="HBase写入流程"><a href="#HBase写入流程" class="headerlink" title="HBase写入流程"></a>HBase写入流程</h2><ol>
<li>Client请求的zookeeper,获取hbase:meta表信息,根据写入的行键获取对应的RegionServer信息</li>
<li>Client请求RegionServer发起写入请求</li>
<li>RegionServer接收到请求后将数据写入到行键对应的Region中.</li>
<li>RegionServer反馈写入状态给Client</li>
<li>关闭写入流</li>
</ol>
<h2 id="BloomFilter-布隆过滤器"><a href="#BloomFilter-布隆过滤器" class="headerlink" title="BloomFilter (布隆过滤器)"></a>BloomFilter (布隆过滤器)</h2><pre><code>判断数据是否存在，如果反馈结果为不存在，是可信的，如果反馈结果为存在，可能有误差
</code></pre>
<p>缩小数据违取范围<br><img src="https://cdn.lovepp.xyz/blog/HCIA/img_17.png!vip" alt="布隆过滤器"></p>
<p>在HBase中行键是以字典序进行排序<br><img src="https://cdn.lovepp.xyz/blog/HCIA/img_18.png!vip" alt="以字典序进行排序"></p>
<h2 id="HBase-Shell命令"><a href="#HBase-Shell命令" class="headerlink" title="HBase Shell命令"></a>HBase Shell命令</h2><pre><code class="sql">namespace:
    create_namespace &#39;名称&#39;
    list_namespace
    list_namespace_ tables &#39;ns1&#39;
    alter_namespace &#39;ns1 ,&#123;属性名称=&gt; &#39;属性值&#125;
    drop_ namespace &#39;ns1&#39; ---命名空间需要是空的

ddl:数据定义语言---&gt; 表层面的操作
    create &#39;表名&#39;,列族名1&#39;;列族2&#39;
    create &#39;表名,&#123;NAME= &gt; &#39;列族&#39; VERSIONS= &gt; 5&#125;,&#123;NAME= &gt;列族&#39; ,VERSIONS= &gt;5&#125;
    修改列族属性信息、添加列族: alter &#39;表名&#39;,&#123;NAME=&gt; &#39;列族&#39; ,VERSIONS=&gt;5&#125;--&gt;如果列族存在做修改，不存在做添加
    使用list可以查看所有的表:包含default命名空间和自定义命名空间中的表
    查看表信息: describe &#39;表名&#39;
    删除表: drop &#39;表名’--&gt; 禁用状态的表才 能进行删除
    禁用表: disable 表名&#39; /启用表: enable &#39;表名&#39;
    
dml:数据管理语言--&gt; 针对数据层面的操作
    添加数据: put &#39;表名，’行键&quot;,列族:列&quot;,值’--&gt; 默认使用的是系统时间戳
    删除数据: delete &#39;表名&quot;;行键’
    delete表名&#39;,行键&quot;，列族:列&#39;
    delete表名&#39;;行键&quot;,列族列,&#123;TIMESTEMP= &gt;&#39;235652&#39;&#125;
    清空表: truncate &#39;表名&#39;
    数据获取: get &#39;表名&#39;;行键’
    get &#39;表名&#39;行键&quot;;列族列
    get &#39;表名&#39;，&#39;行键&quot;;列族列,&#123;VERSIONS=&gt;3&#125;
    数据扫描: scan &#39;表名&#39;
    scan &#39;表名&quot;&#39;;行键&#39;;列族列,VERSIONS= &gt;3&#125;

snapshot:快照操作--&gt; 针对表创建快照，记录当前指定表的数据信息
    创建快照: snapshot &#39;表名&quot;，&#39;快照名称&#39;
    还原快照: resotre_ snapshot &#39;快照名&#39;
    克隆快照: clone_ snapshot ‘快照名;新表名&#39; ---&gt;把快照中的表内容还原到一-张新表上
    删除快照: delete snapshot &#39;快照名&#39;
</code></pre>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><pre><code>数据仓库，查询分析
</code></pre>
<h2 id="Hadoop生态圈"><a href="#Hadoop生态圈" class="headerlink" title="Hadoop生态圈"></a>Hadoop生态圈</h2><ul>
<li>HDFS存储、 HBase存储提供实时读写功能</li>
<li>MapReduce并行计算、Yarn资源管理和任务调度</li>
<li>ZooKeeper协助分布式应用管理服务</li>
<li>Hive底层使用的是MapReduce做计算，MapReduce的使用对编程人员要求比较高</li>
<li>可以执行SQL类的查询分析计算</li>
</ul>
<h2 id="Hive数据模型"><a href="#Hive数据模型" class="headerlink" title="Hive数据模型"></a>Hive数据模型</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_19.png!vip" alt="Hive数据模型"></p>
<ul>
<li>分区:根据字段值进行划分(指定分区字段,分区字段值相同的记录就存放在一一个分区中)<br>分区在物理上是一个文件夹<br>分区下还可以再有分区和桶<br>在创建表的时候可以指定分区字段<br>分区数量是不固定的</li>
<li>桶:根据值的哈希值进行求余放到对应的桶中<br>桶在物理.上是一-个文件<br>在创建表的时候可以指定有几个桶</li>
<li>表类型:托管表(内部表)、外部表、临时表<br>托管表(internal) :元数据和数据信息都是Hive在管理<br><code>删除时，元数据和数据都会被删除\</code><br>外部表(external) :元数据由Hive管理,但是数据可以提供给其他组件共享<br><code>删除时，只删除元数据，数据信息依旧保留\</code><br>临时表(temporary) :只在当前会话中生效，当会话结束表就会被自动删除</li>
</ul>
<h2 id="Hive数据仓库分层-逻辑分层"><a href="#Hive数据仓库分层-逻辑分层" class="headerlink" title="Hive数据仓库分层(逻辑分层)"></a>Hive数据仓库分层<code>(逻辑分层)</code></h2><ul>
<li>ODS (原数据层，操作数据层) :从数据源获取到的数据</li>
<li>DWD (数据明细层) :根据ODS做数据清洗得到的结果</li>
<li>DWS (数据服务层) :根据DWD进行汇总分析计算</li>
<li>ADS (应用服务层) :根据上层应用的业务需求将DWS数据再一次处理分析得到业务 需要的数据</li>
</ul>
<h2 id="Hive的分层处理的优势"><a href="#Hive的分层处理的优势" class="headerlink" title="Hive的分层处理的优势"></a>Hive的分层处理的优势</h2><ul>
<li>复杂问题简单化:将复杂问题分成多个流程，每个层面执行一-一个流程内容</li>
<li>减少重复开发:不要每次提供给上次应用数据时都要对数据进行清洗汇总操作</li>
<li>隔离原始数据:减少到原数据的依赖，避免因为原数据的原因，导致后续操作无法执行</li>
</ul>
<h2 id="Hive-SQL的使用"><a href="#Hive-SQL的使用" class="headerlink" title="Hive SQL的使用"></a>Hive SQL的使用</h2><pre><code class="sql">DDL:数据定义语言
    创建表: create table &#39;表名(字段类型,字段2类类型... .);
    create external table表名&#39;(字段类型,字段2类型....
    create temporary table &#39;表名&#39;(字段类型,字段2类型... .
    修改表: alter table表名&#39; rename to &#39;新表名;
    alter table &#39;表名&#39; addcolumns (字段类型);
    删除表: drop table &#39;表名&#39;;
    查询数据库中的所有表: show tables;
    查看表信息: describe table &#39;表名&#39;;
    
DML:数据管理语言
    添加数据:从文件中添加到表中
    load data inpath HDFS路径into table表名
    load data local inpath Linux路径into table表名
    load data local inpath Linux路径overwrite into table表
    
    从一个表添加到另-一个表中
    insert into table 表名 select * from 原表 where条件;
    from 原表 insert into table 表名 select * where 条件
    from 原表 insert overwrite table 表名 select 字段 where 条件
    从表中导出到文件中
    insert into directory HDFS路径 select * from表
    insert into local directory Linux 路径select * from 表
    export table 表 to HDFS路径
    
DQL:数据查询语言
    标准查询: select * from表名
    分组: select * from 表名 group by字段
    排序: select * from 表名 order by字段desc
    多表联合查询: select * from (select * from 表 a join 表b  on a.id= b.id)
    
创建表时的特殊操作
    分区: partitioned (字段类型)
    指定列分隔符: row format delimited fields terminated by &#39;分隔符&#39;
    指定外部表的存储路径: location 路径
    指定外部表的存储类型: stored as textfile
    指定字段加密: ROW FORMAT SERDE
    &#39;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#39; WITH SERDEPROPERTIES(
    &#39;column.encode.columns&#39;=&#39;字段1,字段
    2&#39;column.encode.classname&#39; =&#39;org apache.hadoop.hive.serde2.AESRewriter);
</code></pre>
<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="Spark特点"><a href="#Spark特点" class="headerlink" title="Spark特点"></a>Spark特点</h2><pre><code>轻快灵巧Spark的处理能力是MapReduce的30倍，处理能力不容易受到任务量增加的影响
</code></pre>
<p>轻:底层代码只有3万行，使用的函数式编程语言scala<br>快:处理速度快<br>灵:提供很多不同层面的处理功能<br>巧:巧妙的应用Hadoop平台</p>
<h2 id="RDD-分布式数据集、可分区的"><a href="#RDD-分布式数据集、可分区的" class="headerlink" title="RDD:分布式数据集、可分区的"></a>RDD:分布式数据集、可分区的</h2><ul>
<li>具有血统机制(RDD由父RDD执行操作之后产生)</li>
<li>如果子RDD丢失，RDD故障，重新执行父RDD就可以重新得到的子RDD</li>
<li>RDD默认存储在内存中，如果内存不足的时候，发生溢写</li>
<li>Spark节点会分配60%的内存用于做缓存，40%执行内存</li>
</ul>
<h2 id="依赖类型"><a href="#依赖类型" class="headerlink" title="依赖类型"></a>依赖类型</h2><pre><code>宽依赖、窄依赖
</code></pre>
<ul>
<li>窄依赖:父RDD的每个分区都只会被<code>一个</code>子RDD的分区所依赖</li>
<li>宽依赖:父RDD的每个分区可能会被<code>多个子RDD的分区所依赖</code></li>
</ul>
<h2 id="Stage划分"><a href="#Stage划分" class="headerlink" title="Stage划分"></a>Stage划分</h2><pre><code>遇到窄依赖就加入，宽依赖就断开，剩余的所有RDD被放在一个Stage中
</code></pre>
<h2 id="RDD操作类型"><a href="#RDD操作类型" class="headerlink" title="RDD操作类型"></a>RDD操作类型</h2><ul>
<li>创建操作:创建RDD用于接收数据结果</li>
<li>原始RDD:读取数据源获得的RDD (readFile(path))</li>
<li>转换得来:通过父RDD执行操作后得到的子RDD</li>
<li>控制操作:持久化RDD,可以持久化到内存或磁盘中,默认存在内存</li>
<li>转换操作:可对RDD执行的处理操作，转换操作是懒惰的，转换操作并不是立马执行，遇到行动操作才执行</li>
<li>行动操作:实际调用Spark执行(存储文件,数据输出等)</li>
</ul>
<ul>
<li>transformation算子在整个程序中 -&gt;声明转换操作,实际并没有执行</li>
<li>action算子时， 会从第一-个操作开始执行</li>
<li>DataFrame:属于一个DataSet实例， 不可变的弹性分布式数据集，存储数据时不止存储数据内容,存储数据对应结构信息及类型</li>
<li>DataSet:以对象的形式存储数据集，DataFrame= DataSet[Row]</li>
</ul>
<h2 id="RDD、DataFrame、-DataSet数据集的联系"><a href="#RDD、DataFrame、-DataSet数据集的联系" class="headerlink" title="RDD、DataFrame、 DataSet数据集的联系"></a>RDD、DataFrame、 DataSet数据集的联系</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_20.png!vip" alt="数据集的联系"></p>
<h2 id="Spark体系架构"><a href="#Spark体系架构" class="headerlink" title="Spark体系架构"></a>Spark体系架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_21.png!vip" alt="Spark体系架构"></p>
<ul>
<li>集群部署形式: <br>Standalone: spark自 己管理资源调度<br>Spark On Yarn:使用yarn做资源管理调度 <br>Mesos: AMR实验室开发的资源管理器，最适用于Spark的资源管理器</li>
<li>Spark Core:处理核心</li>
<li>Spark SQL:处理结构化数据，使用Hive元数据</li>
<li>Spark Streaming:实时流处理(实际微批处理) , 能够低延迟的计算反馈结果</li>
<li>MLLib:机器学习,根据历史数据进行建模，根据模型和提供的数据进行数据预测</li>
<li>GraphX:图计算,主要用于关系统计,关系查询</li>
<li>SparkR: R语言库,提供R语言接口，可以使用R语言操作Spark</li>
<li>Structured Streaming:流处理，将数据存入-个无边界表(新数据不断添加，旧数据不断移除)使用增量的方式获取表数据内容进行执行</li>
</ul>
<h1 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h1><pre><code>分布式流处理组件
</code></pre>
<h2 id="关键特性-实时响应，延迟性低"><a href="#关键特性-实时响应，延迟性低" class="headerlink" title="关键特性:实时响应，延迟性低"></a>关键特性:实时响应，延迟性低</h2><ul>
<li>数据不存储先执行(离线处理先存储数据然后再执行)</li>
<li>连续查询(程序运行后就不终止,除非系统故障导致的终止或者手动停止)</li>
<li>事件驱动:传入的数据信息触动任务处理</li>
</ul>
<h2 id="Streaming系统架构"><a href="#Streaming系统架构" class="headerlink" title="Streaming系统架构"></a>Streaming系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_22.png!vip" alt="Streaming系统架构"></p>
<ul>
<li>Client:客户端接口</li>
<li>Nimbus (主节点) :接收客户端的请求，管理Supervisor从节点，管理任务分配，编写任务书</li>
<li>Supervisor (从节点) :实行任务，管理worker</li>
<li>Worker (进程) :程序执行</li>
<li>Executor (线程) :每个Executor中默认执行一 一个Task</li>
<li>Task (任务) : Task分别对应每一 个Spout/Bolt组件的执行 </li>
<li>ZooKeeper:监控Nimbus主节点的状态，如果主节点故障切换备用节点<br>监控Supervisor从节点状态，如果从节点故障,通知Nimbus迁移任务，启动自动恢复<br>接收Nimbus任务书，将每个从节点的任务存放在每个Supervisor自己对应的目录中</li>
</ul>
<h2 id="Streaming任务架构"><a href="#Streaming任务架构" class="headerlink" title="Streaming任务架构"></a>Streaming任务架构</h2><ul>
<li>Topology:拓扑结构,封装任务执行流程</li>
<li>Spout:发送数据源的组件,接收第三方数据收集I具提供的数据发送到数据流</li>
<li>每个应用只有一个spout</li>
<li>Bolt:从数据流中获取数据,执行数据处理，如果当前bolt不是最后-个执行程序将结果放回数据流一个应用中可以有多个bolt</li>
<li>Tuple:数据流中的数据格式，组件之间数据传输的格式，元组中包含两个参数(id, stream)</li>
</ul>
<h2 id="Streaming执行任务"><a href="#Streaming执行任务" class="headerlink" title="Streaming执行任务"></a>Streaming执行任务</h2><ol>
<li>用户通过Client提交应用到Nimbus中</li>
<li>Nimbus接收到应用后，根据应用情况及当前集群的从节点情况编写任务书</li>
<li>将任务书.上传到ZooKeeper中</li>
<li>ZooKeeper接收到任务书后根据每个节点将对应的任务存放在节点对应的目录下</li>
<li>Supervisor周期性监测自己在ZooKeeper中的目录有没有新任务</li>
<li>Supervisor发现新任务，根据任务书内容从Nimbus中下载任务所需要的jar包</li>
<li>Supervisor执行任务,反馈执行状态给Nimbus .</li>
<li>Nimbus将任务状态反馈给Client</li>
</ol>
<h2 id="根据任务架构执行"><a href="#根据任务架构执行" class="headerlink" title="根据任务架构执行"></a>根据任务架构执行</h2><ol>
<li>获取拓扑结构</li>
<li>根据拓扑结构分别找到每一流程的处理单元</li>
<li>按照路程执行处理单元</li>
</ol>
<h2 id="消息传递语义"><a href="#消息传递语义" class="headerlink" title="消息传递语义"></a>消息传递语义</h2><ul>
<li>最多一次:数据发送只发送一次, 可靠性最低，吞吐量最大<br>  缺点:可能存在数据丢失的情况<br>  优点:数据一定不会被重复执行</li>
<li>最少一次:数据可能会发送多次，可靠性高，吞吐量较小<br>  优点:数据不会丢失<br>  缺点:数据可能会被重复执行</li>
<li>仅有一次(精准一次) :数据就发送一-次, 并且保证发送成功，可靠性高，吞吐量最低<br>  优点:数据不会丢失，且数据不被重复处理<br>  缺点:消耗的资源和时间较多</li>
</ul>
<h2 id="Ack机制-消息传输最少一次"><a href="#Ack机制-消息传输最少一次" class="headerlink" title="Ack机制(消息传输最少一次)"></a>Ack机制(消息传输最少一次)</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_23.png!vip" alt="Ack机制"></p>
<h1 id="Fink"><a href="#Fink" class="headerlink" title="Fink"></a>Fink</h1><pre><code>分布式实时计算引擎(流处理引擎)
</code></pre>
<h2 id="Flink-VS-Spark-Streaming"><a href="#Flink-VS-Spark-Streaming" class="headerlink" title="Flink VS Spark Streaming"></a>Flink VS Spark Streaming</h2><ul>
<li>Flink可以做流处理(侧重)也可以做批处理，底层引擎属于流处理引擎</li>
<li>通过流处理引擎模拟批处理形式实现的批处理</li>
<li>Spark可以做流处理也可以做批处理(侧重点)，底层弓|擎属于批处理引擎</li>
<li>通过批处理引擎,模拟流处理实现的流处理功能</li>
</ul>
<h2 id="Flink的关键特性"><a href="#Flink的关键特性" class="headerlink" title="Flink的关键特性"></a>Flink的关键特性</h2><pre><code>状态、时间、窗口、检查点
</code></pre>
<h2 id="Flink系统架构"><a href="#Flink系统架构" class="headerlink" title="Flink系统架构"></a>Flink系统架构</h2><p><img src="https://cdn.lovepp.xyz/blog/HCIA/img_24.png!vip" alt="Flink系统架构"></p>
<ul>
<li>部署形式: Local (单机版部署)<br>  Cluster (Standalone: Flink集群自己管理资源调度<br>  Yarn:借助Yarn组件帮助管理协调资源和任务)<br>  Clound (云部署)</li>
<li>Flink核心模块: Runtime (不管是流处理还是批处理都是在Runtime中执行)</li>
<li>接口层: DataStream (流处理)和DataSet (批处理)</li>
<li>Table API &amp; SQL:处理结构化数据<br>```sql<br>Table API:将操作应用封装成方法<br>  select(“t_ demo “).where(“条件”)</li>
</ul>
<p>SQL:基于Table API使用，<br>    sqlQuery(“select * from t_ demo where条件”)</p>
<pre><code>
## 有界流和无界流
- 有界流:知道开始，知道结束，使用批处理处理有界流数据.
- 无界流:知道开始，不知道结束，使用流处理接口进行数据处理

## DataStream:用于存储数据的数据集，只能执行流处理操作
- 基于流处理运行环境获取到的数据

## DataSet:用来接收数据的数据集，只能执行批处理操作
- 基于批处理运行环境获取到的数据

`并不能在一个应用中同时接收流处理和批处理接口，以此实现流处理和批处理的共用`


## Flink运行流程

![Flink运行流程](https://cdn.lovepp.xyz/blog/HCIA/img_25.png!vip)

1. DataSource:接收数据输入，从数据源获取数据
2. Transformations:数据转换，数据处理过程
3. DataSink:将最终数据结果输出到指定位置(如HDFS、 HBase、 文件、数据库等)

## Flink程序运行流程
`1. 创建运行环境流处理/批处理`
2. 通过运行环境对象获取数据源数据(DataStream/DataSet)
3. 针对数据集进行数据转换
4. 将最终结果进行输出(批处理的print算子)
`5. 最后执行程序(行动算子) executor()`

## Flink运行程序
![Flink运行程序](https://cdn.lovepp.xyz/blog/HCIA/img_26.png!vip)

1. Client向JobManager发起请求
2. Client对任务进行优化等操作
3. JobManager分配任务给TaskManager
4. TaskManager接收到任务后执行任务
5. TaskManager反馈任务执行状态给JobManager
6. JobManager统一反馈给用户

- Flink Client:用户通过Client连接到JobManager
- JobManager (主节点) :接收用户请求，管理资源任务分配，管理从节点信息
- TaskManager (从节点) :接收任务处理任务，反馈给主节点
- Standalone部署:创建Task Slot: Flink的抽象资源

## Flink状态
    区别于其他组件的一-个特性，支持状态管理(中间结果状态)

## Fink窗口类型
- 滑动窗口: 窗口移动方式是平移,设定参数时需要设定窗口大小,滑动距离.窗口大小固定,可能会出现数据源重复和数据丢失的情况
- 滚动窗口: 窗口移动方式滚动,滚动距离就是窗口大小,设定窗口时只需要设定窗口大小.窗口大小固定,不会出现数据重复或者数据丢失的情况,会出现空窗口的情况
- 会话窗口: 由会话启动的窗口,设定过期时间,窗口代销不固定,运行时不会有丢失的数据,不会出现空窗口
- 时间窗口: 以时间为条件设定的窗口,`分别可以再分为滑动或滚动`
- 数量窗口: 由会话启动的窗口,设定过期时间,`分别可以再分为滑动或滚动`

## Fink的时间类型
- 时间类型: 事件发生的时间 
- 时间类型: 时间达到处理系统的时间
- 处理时间(默认): 时间被处理的时间
- 时间乱序问题: 事件被处理的顺序不是时间产生顺序
- 时间乱序原因: 数据受到数据传输影响


## Watermark(水位线/水印): 解决数据乱序问题
- 设定水位线时间,当水位线设定的时间时间也达到系统时,就会触发窗口执行
- 可设置水位线延迟,可允许窗口延迟触发\




## 对于延迟数据的处理方式
- 丢弃(默认): 当窗口已经被触发过,该窗口的数据达到也会被丢弃,不会被执行
- 可允许延迟: 设定可允许延迟时间,窗口已经被执行,但是输在可允许延迟时间达到,重新重发窗口的执行\
  `allowedLateness`(可延迟时间)
- 收集后做统一处理: 把所有的延迟数据收集起来,在程序最后做统一处理\
`OutputTag&lt;T&gt; lateOutputTag = new OutputTag //用于存放延迟数据的数据集`\
`.side0utputLateData(late0utputTag)`

## Flink容错性 (CheckPoint实现)
1. `CheckPoint:检查点，自动触发,当任务结束后会自动删除`
    - 保存当前任务状态，周期性触发,默认情况下不启动检查点
    - 在启动检查点时就可以设定周期时间，单位ms: .enableCheckPointing(10000)
    - 修改消息传输语义(默认情况仅有一次): .setCheckPointMode(CheckPointMode.AT_LEAST_ONCE)
    - 快照超时时间:防止一个问题快照影响大量快照创建堆积: .setCheckpointingTimeout(60000)
    - 可以设定检查点之间的最小间隔时间
    - 可以设定最大并行执行数量
    - 设定外部检查点:可以把检查点信息存储于在外部系统中，不会因为Flink系统问题受到影响
2. SavePoint:保存点，底层CheckPoint, 手动触发,任务结束后也依旧保留

## 状态保存
内存:默认，state和checkpoint都存储在内存，只是用本地测试
文件系统: state在内存， checkpoint在文件系统中
数据库: state存储在内置数据库中，checkpoint在文件系统中，针对大量数据任务处理的场景

# 转载连接
## ![Chenci&#39;s blog：华为HCIA](https://chencicici.github.io/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/)
</code></pre>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://www.uodrad.tk/2022/04/20/2022-4-20/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HCIA/" rel="tag">HCIA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2022/01/08/Fuck-Ivce/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Python网易职教云（MooC）刷课</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.staticfile.org/valine/1.4.16/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "4zd9J8JtWvgAna2eJx8eOdUv-gzGzoHsz",
    app_key: "n12qRUkYT4zvH8FHSshMR5cS",
    path: window.location.pathname,
    avatar: "retro",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020-2022
        <i class="ri-heart-fill heart_icon"></i> UodRad
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="http://uodrad-image.test.upcdn.net/blog/logo.png" alt="UodRad的博客"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯奶茶吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="http://uodrad-image.test.upcdn.net/blog/alipay.jpg!vip">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="http://uodrad-image.test.upcdn.net/blog/wechat.png!vip">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->
 
<script src="/js/clickLove.js"></script>
 
<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1393411383&auto=0&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
</body>

</html>